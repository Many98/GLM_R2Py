{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Many98/GLM_R2Py/blob/main/Python/01ZLMA_ex03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-i6MbNFm4Zt"
   },
   "source": [
    "# 01ZLMA - Exercise 03\n",
    "Exercise 03 of the course 01ZLMA. \n",
    "\n",
    "## Contents\n",
    "\n",
    "* Statistical Inference\n",
    " ---\n",
    "* Testing\n",
    " ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "593Mg4ZbbeEE"
   },
   "source": [
    "#  Necessary theory recap from Lecture 04\n",
    "\n",
    "Under the conditions of regularity holds\n",
    "\n",
    "1.  $ \\ U(\\beta) \\sim N_{p}(0,I(\\beta)) \\Rightarrow  I^{-\\frac{1}{2}}(\\beta)\\, U(\\beta) {\\stackrel{D}{\\longrightarrow}} N_{p}(0, 1)$\n",
    "2. $ U(\\beta)I^{-1}(\\beta)U(\\beta)\\sim \\chi^{2}(p) \\Rightarrow U(\\beta)^T I^{-1}(\\beta)U(\\beta)  {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "3. Consistency of $\\hat{\\beta}$ and Wald statistics: \\\\\n",
    " $\\hat{\\beta}\\sim N_{p}(\\beta,I^{-1}(\\beta)) \\Rightarrow\n",
    "(\\hat{\\beta}-\\beta)^T I(\\beta)(\\hat{\\beta}-\\beta) {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2c7jDIXSGGL"
   },
   "source": [
    "Saturated and null model\n",
    "\n",
    "* Null model: $\\mu_i = \\mu, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Null Model assumes one parameter for all of the data points, which means you only estimate 1 parameter. \n",
    "* Saturated model: $Y_i = \\hat{\\mu_i}, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Saturated Model is a model that assumes each data point has its own parameters, which means you have n parameters to estimate.\n",
    "* Proposed Model:  model, where you try to explain your data points with $p$ parameters + an intercept term, so you have p+1 parameters, where $1 \\leq p \\leq n$.\n",
    "\n",
    "Questions:\n",
    "* What is the difference between null and saturated model?\n",
    "* Which model has greater log-likelihoood value?\n",
    "* Which model has the highest log-likelihood value?\n",
    "* What can you say about asymptotic distributions of $\\hat{\\beta}$ and $U(\\hat{\\beta})$ for saturated model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um9ho8cQHobx"
   },
   "source": [
    "## Let's code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from helpers import F, chisq, rao, DiagnosticPlots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-kZTsg7FZoM"
   },
   "source": [
    "Use Example 2 from the last Exercise 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n  = 20 # n observations\n",
    "m  = 2 # m parameters to estimate\n",
    "X1 = np.ones((n*m,))  # Intercept\n",
    "X2 = np.array([i for i in range(1, n+1)] * m) # Regressors\n",
    "X = np.vstack([X1, np.log(X2)]).T # design matrix\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m) # Response variable with Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jU_eFKcbWMUy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -126.97\n",
      "Date:                Mon, 05 Sep 2022   Deviance:                       35.745\n",
      "Time:                        10:30:29   Pearson chi2:                     36.0\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9067      0.130      6.999      0.000       0.653       1.161\n",
      "x1             1.2878      0.049     26.044      0.000       1.191       1.385\n",
      "==============================================================================\n",
      "estimated params are:[0.90670123 1.28781163]\n",
      "fitted values are:[  2.47614083   6.04568159  10.1910197   14.76098025  19.67510418\n",
      "  24.88213087  30.34606782  36.04002866  41.9430435   48.03822691\n",
      "  54.31164419  60.75156898  67.34797519  74.09217651  80.97656313\n",
      "  87.99440445  95.13969827 102.40705324 109.79159587 117.28889586\n",
      "   2.47614083   6.04568159  10.1910197   14.76098025  19.67510418\n",
      "  24.88213087  30.34606782  36.04002866  41.9430435   48.03822691\n",
      "  54.31164419  60.75156898  67.34797519  74.09217651  80.97656313\n",
      "  87.99440445  95.13969827 102.40705324 109.79159587 117.28889586]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to create models we can use standard api or formula (r-like) api in statsmodels\n",
    "# formula api requires dataset (pandas) and formula\n",
    "d = pd.DataFrame(data={'Y': Y, 'X1': X1, 'X2':X2})\n",
    "#model = smf.glm(formula='Y~np.log(X2)', data=d, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# standard api requires specifying endog (response) and exog (explanatory) design matrices\n",
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "beta_e = model.params; print(f'estimated params are:{beta_e}')\n",
    "y_hat = model.predict(); print(f'fitted values are:{y_hat}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2, Y, color='red', marker='o')\n",
    "ax.plot(np.unique(y_hat), color='blue')\n",
    "ax.set_title('Poisson model')\n",
    "ax.set_xlabel('Year Quoter')\n",
    "ax.set_ylabel('Number of cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N8x-oi3HAKK"
   },
   "source": [
    "Repetition using custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calcualate weights W\n",
    "def calc_W_inv(X, beta):\n",
    "    return np.diag(np.exp(X @ beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xcA9wuh1WMtL"
   },
   "outputs": [],
   "source": [
    "# function to calcualate weights Z\n",
    "def calc_Z(X,Y,beta):\n",
    "    return X@beta + (Y - np.exp(X@beta)) / np.exp(X@beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "igkUvl36XAGV"
   },
   "outputs": [],
   "source": [
    "# IWLS for example 2\n",
    "\n",
    "def IWLS(X,Y,beta_init,maxiter,epsilon):\n",
    "    res = {'FM': None, 'SV': None, 'betas': None}\n",
    "    # Fisher-scoring algorithm\n",
    "    i = 1     # first iteration\n",
    "\n",
    "    beta_i = beta_init\n",
    "    \n",
    "    while i <= maxiter:\n",
    "        W = calc_W_inv(X,beta_i)\n",
    "        Z = calc_Z(X,Y,beta_i)\n",
    "        beta_pred = beta_i\n",
    "        beta_i = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        diff = np.max(np.abs(beta_i - beta_pred))\n",
    "        if diff < epsilon:\n",
    "            break\n",
    "        W = calc_W_inv(X, beta_i)\n",
    "        Z = calc_Z(X, Y, beta_i)\n",
    "\n",
    "        res['SV'] = X.T@W@Z\n",
    "        res['FM'] = X.T@W@X\n",
    "        res['betas'] = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1VDw0-mqZF7x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of parameters: [0.90670123 1.28781163]\n",
      "Estimated Fisher information matrix: [[ 2169.          5603.56588275]\n",
      " [ 5603.56588275 14885.67889348]]\n",
      "Estimated covariance matrix: [[ 0.01678041 -0.00631682]\n",
      " [-0.00631682  0.00244508]]\n"
     ]
    }
   ],
   "source": [
    "# Estimation of betas\n",
    "result1 = IWLS(X,Y,np.ones(2),100,10^(-6))\n",
    "print(f'Estimation of parameters: {result1[\"betas\"]}')      # Estimation of parameters\n",
    "print(f'Estimated Fisher information matrix: {result1[\"FM\"]}')        # Estimated Fisher information matrix\n",
    "print(f'Estimated covariance matrix: {np.linalg.inv(result1[\"FM\"])}')  # Estimated covariance matrix  = Inverse of estimated Fisher information matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEUlAqmFH_mB"
   },
   "source": [
    "Comparison of our custom solution with the built in glm function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6E-UbtQQXALw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -126.97\n",
      "Date:                Mon, 05 Sep 2022   Deviance:                       35.745\n",
      "Time:                        10:30:29   Pearson chi2:                     36.0\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9067      0.130      6.999      0.000       0.653       1.161\n",
      "x1             1.2878      0.049     26.044      0.000       1.191       1.385\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.01678036 -0.0063168 ]\n",
      " [-0.0063168   0.00244508]]\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aic\n",
      "bic\n",
      "bic_deviance\n",
      "bic_llf\n",
      "bse\n",
      "conf_int\n",
      "converged\n",
      "cov_kwds\n",
      "cov_params\n",
      "cov_type\n",
      "deviance\n",
      "df_model\n",
      "df_resid\n",
      "f_test\n",
      "family\n",
      "fit_history\n",
      "fittedvalues\n",
      "get_hat_matrix_diag\n",
      "get_influence\n",
      "get_prediction\n",
      "info_criteria\n",
      "initialize\n",
      "k_constant\n",
      "llf\n",
      "llf_scaled\n",
      "llnull\n",
      "load\n",
      "method\n",
      "mle_settings\n",
      "model\n",
      "mu\n",
      "nobs\n",
      "normalized_cov_params\n",
      "null\n",
      "null_deviance\n",
      "params\n",
      "pearson_chi2\n",
      "plot_added_variable\n",
      "plot_ceres_residuals\n",
      "plot_partial_residuals\n",
      "predict\n",
      "pseudo_rsquared\n",
      "pvalues\n",
      "remove_data\n",
      "resid_anscombe\n",
      "resid_anscombe_scaled\n",
      "resid_anscombe_unscaled\n",
      "resid_deviance\n",
      "resid_pearson\n",
      "resid_response\n",
      "resid_working\n",
      "save\n",
      "scale\n",
      "summary\n",
      "summary2\n",
      "t_test\n",
      "t_test_pairwise\n",
      "tvalues\n",
      "use_t\n",
      "wald_test\n",
      "wald_test_terms\n"
     ]
    }
   ],
   "source": [
    "# to find out what params has `model` object\n",
    "for attr in dir(model):\n",
    "    if not attr.startswith('_'):\n",
    "        print(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7vo_sJaOFiL"
   },
   "source": [
    "Asymptotics:\n",
    "\n",
    "* $ (\\hat{\\beta} - \\beta) \\sim N_{p}(0, I^{-1}(\\beta))$ \n",
    "* Estimated Fisher information matrix  $\\hat{I}(\\hat{\\beta}) = (X^T \\hat{W} X)$  matrix.\n",
    "*  Estimated covariance matrix $\\hat{V} (\\hat{\\beta}) = (X^T \\hat{W} X)^{-1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kB52Ef03Z7uO"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "repet = 50\n",
    "n_observ = np.array([1,2,5,10,100, 500])\n",
    "betas_hat = np.zeros((6, repet, 2))\n",
    "\n",
    "for _, i in enumerate(n_observ):\n",
    "    for j in range(repet):\n",
    "        X1 = np.ones((n*i,))\n",
    "        X2 = np.array([i for i in range(1, n+1)]*i)\n",
    "        X  = np.vstack([X1, np.log(X2)]).T\n",
    "        beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "        lamdas = np.exp(X @ beta) # Means\n",
    "        Y = np.random.poisson(lamdas, n*i)\n",
    "        betas_hat[_, j] = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit().params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nkafuLnXZ7xG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 10\n",
      "[[ 0.06331909 -0.03191666]\n",
      " [-0.03191666  0.01722532]]\n",
      "-0.003279473466319034\n",
      "Number of observations: 20\n",
      "[[ 0.02767185 -0.01311611]\n",
      " [-0.01311611  0.00680741]]\n",
      "0.004674668489691549\n",
      "Number of observations: 50\n",
      "[[ 0.02174203 -0.01075697]\n",
      " [-0.01075697  0.00555429]]\n",
      "-0.0038141838145937935\n",
      "Number of observations: 100\n",
      "[[ 0.01153541 -0.00578641]\n",
      " [-0.00578641  0.00304221]]\n",
      "-0.0015135688288840765\n",
      "Number of observations: 1000\n",
      "[[ 0.00078645 -0.00039033]\n",
      " [-0.00039033  0.00020358]]\n",
      "-0.0009172027950050831\n",
      "Number of observations: 5000\n",
      "[[ 1.30742802e-04 -6.47378627e-05]\n",
      " [-6.47378627e-05  3.36466987e-05]]\n",
      "0.0005952070205275229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(n_observ)):\n",
    "    print(f\"Number of observations: {n_observ[i]*n}\")\n",
    "    print(np.cov((betas_hat[i] - beta).T))\n",
    "    print(np.mean(betas_hat[i] - beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TjcOg79UPRM"
   },
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Use the model from the beginning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8rwWB0Grrmnt"
   },
   "outputs": [],
   "source": [
    "n  = 20\n",
    "m  = 2\n",
    "\n",
    "X1 = np.ones((n*m,))\n",
    "X2 = np.array([i for i in range(1, n+1)]*m)\n",
    "X  = np.vstack([X1, np.log(X2)]).T\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2opFFdr0UfhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -124.60\n",
      "Date:                Mon, 05 Sep 2022   Deviance:                       33.462\n",
      "Time:                        10:30:30   Pearson chi2:                     31.4\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.7449      0.133      5.608      0.000       0.485       1.005\n",
      "x1             1.3556      0.051     26.842      0.000       1.257       1.455\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.01764151 -0.00662072]\n",
      " [-0.00662072  0.00255045]]\n"
     ]
    }
   ],
   "source": [
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR3DTTTWV94T"
   },
   "source": [
    "Calculation of Z value\n",
    " $$Z_i = \\frac{\\hat{\\beta_i}}{(I^{-1}(\\hat{\\beta_i}))_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lv8guvybUK-E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -124.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 05 Sep 2022</td> <th>  Deviance:          </th> <td>  33.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:30:30</td>     <th>  Pearson chi2:      </th>  <td>  31.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7449</td> <td>    0.133</td> <td>    5.608</td> <td> 0.000</td> <td>    0.485</td> <td>    1.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3556</td> <td>    0.051</td> <td>   26.842</td> <td> 0.000</td> <td>    1.257</td> <td>    1.455</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -124.60\n",
       "Date:                Mon, 05 Sep 2022   Deviance:                       33.462\n",
       "Time:                        10:30:30   Pearson chi2:                     31.4\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7449      0.133      5.608      0.000       0.485       1.005\n",
       "x1             1.3556      0.051     26.842      0.000       1.257       1.455\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing statistics from summary table\n",
    "model.summary()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dNjECz1FNw_c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.60847867 26.84220129]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By definition\n",
    "\n",
    "z_stat = model.params / np.sqrt(np.diag(model.cov_params()))\n",
    "print(z_stat)\n",
    "z_stat == model.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9mHfejdWULDh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval: [2.04112847e-008 1.04019671e-158]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-values of the test\n",
    "p_val = 2*scipy.stats.norm.sf(z_stat, loc=0, scale=1)\n",
    "print(f'pval: {p_val}')\n",
    "p_val == model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7GdfbeqdYOIv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5% CI = 1.256601446955522,ESTIM = 1.3555834455886617, 97.5% CI = 1.4545654442218015\n",
      "[[0.48460059 1.00525065]\n",
      " [1.25660145 1.45456544]]\n"
     ]
    }
   ],
   "source": [
    "### 100(1-alpha) confidence interval\n",
    "alpha = 0.05\n",
    "u = scipy.stats.norm.ppf(1-alpha/2,0,1)\n",
    "CI_LB = model.params[1] - u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "CI_UB = model.params[1] + u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "\n",
    "print(f\"2.5% CI = {CI_LB},ESTIM = {model.params[1]}, 97.5% CI = {CI_UB}\")\n",
    "\n",
    "\n",
    "# built in function\n",
    "print(model.conf_int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkhFJFXceHjn"
   },
   "source": [
    "Question:\n",
    "\n",
    "* Compare hypothesis testing in LM vs. GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwXaIg0peQee"
   },
   "source": [
    "# Deviance\n",
    "\n",
    "Deviance is a measure of goodness of fit of a GLM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjNUyZoZeStY"
   },
   "source": [
    "Log-likelihood of the saturated model is the highest possible one with given data, $\\tilde{\\mu}_i = y_i$ and $\\tilde{\\theta_i} = \\theta(y) = (b')^{-1}(y_i)$.\n",
    "$$l(\\tilde{\\mu},\\phi;y)=\\sum_{i=1}^{n}\\frac{y_{i}\\tilde{\\theta}_{i}-b(\\tilde{\\theta}_{i})}{a_{i}(\\phi)}+\\sum_{i=1}^{n}c(y_i,\\phi)$$\n",
    "\n",
    "Scale deviance statistics:\n",
    "$${S(y,\\hat{\\mu},\\phi)}=2\\left[l(\\tilde{\\mu},\\phi;y)-l(\\hat{\\mu},\\phi;y)\\right]\n",
    "=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}(\\phi)}.\n",
    "$$\n",
    "\n",
    "Deviance:\n",
    "Let $a_{i}(\\phi)=a_{i}\\phi$, then\n",
    "$$S(y,\\hat{\\mu},\\phi)=\\frac{D(y,\\hat{\\mu})}{\\phi},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "D(y,\\hat{\\mu})=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}}\n",
    "$$\n",
    "\n",
    "### Comparison of two models\n",
    "\n",
    "Assume model $D_0$ with $p_0$ paramters and its sub-model $D_1$ with $p_1$ parameters, then\n",
    "$$ \\frac{1}{\\phi} (D_0 - D_1) \\sim \\chi(p_0 - p_1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLxMlbIKeTe5"
   },
   "source": [
    "Question:\n",
    "* Can we take deviance as a measure of the model quality?\n",
    "* Can we use deviance as a measure of the saturated model quality?\n",
    "* Complete the sentence: Compare two GLMs with deviance is like compare two LMs with ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5PVvXp_SpDUx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -124.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 05 Sep 2022</td> <th>  Deviance:          </th> <td>  32.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:30:30</td>     <th>  Pearson chi2:      </th>  <td>  30.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8042</td> <td>    0.149</td> <td>    5.409</td> <td> 0.000</td> <td>    0.513</td> <td>    1.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3445</td> <td>    0.052</td> <td>   25.889</td> <td> 0.000</td> <td>    1.243</td> <td>    1.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0719</td> <td>    0.082</td> <td>   -0.875</td> <td> 0.382</td> <td>   -0.233</td> <td>    0.089</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       37\n",
       "Model Family:                 Poisson   Df Model:                            2\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -124.22\n",
       "Date:                Mon, 05 Sep 2022   Deviance:                       32.697\n",
       "Time:                        10:30:30   Pearson chi2:                     30.5\n",
       "No. Iterations:                     6   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8042      0.149      5.409      0.000       0.513       1.096\n",
       "x1             1.3445      0.052     25.889      0.000       1.243       1.446\n",
       "x2            -0.0719      0.082     -0.875      0.382      -0.233       0.089\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add random variable to the previous model \n",
    "Z = scipy.stats.uniform.rvs(loc=0, scale=1, size=n*m)\n",
    "model_0 = sm.GLM(endog=Y, exog=np.hstack([X, Z[:, None]]), family=sm.families.Poisson()).fit()\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_O24NMRTPjoA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -124.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 05 Sep 2022</td> <th>  Deviance:          </th> <td>  33.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:30:30</td>     <th>  Pearson chi2:      </th>  <td>  31.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7449</td> <td>    0.133</td> <td>    5.608</td> <td> 0.000</td> <td>    0.485</td> <td>    1.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3556</td> <td>    0.051</td> <td>   26.842</td> <td> 0.000</td> <td>    1.257</td> <td>    1.455</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -124.60\n",
       "Date:                Mon, 05 Sep 2022   Deviance:                       33.462\n",
       "Time:                        10:30:30   Pearson chi2:                     31.4\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7449      0.133      5.608      0.000       0.485       1.005\n",
       "x1             1.3556      0.051     26.842      0.000       1.257       1.455\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proposed model\n",
    "m1 = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson())\n",
    "model_1 = m1.fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WbtdZzD6Pjx6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    39</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -689.77</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 05 Sep 2022</td> <th>  Deviance:          </th> <td>  1163.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:30:30</td>     <th>  Pearson chi2:      </th> <td>1.02e+03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th> <td>1.710e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.0069</td> <td>    0.021</td> <td>  187.897</td> <td> 0.000</td> <td>    3.965</td> <td>    4.049</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       39\n",
       "Model Family:                 Poisson   Df Model:                            0\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -689.77\n",
       "Date:                Mon, 05 Sep 2022   Deviance:                       1163.8\n",
       "Time:                        10:30:30   Pearson chi2:                 1.02e+03\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):          1.710e-14\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.0069      0.021    187.897      0.000       3.965       4.049\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null model\n",
    "\n",
    "model_n = sm.GLM(endog=Y, exog=X[:, 0], family=sm.families.Poisson()).fit()\n",
    "model_n.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "508GBQM_Pj5L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                        0\n",
      "Model Family:                 Poisson   Df Model:                           39\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -107.87\n",
      "Date:                Mon, 05 Sep 2022   Deviance:                   5.6416e-09\n",
      "Time:                        10:30:30   Pearson chi2:                 2.82e-09\n",
      "No. Iterations:                    23   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.6931      0.707      0.980      0.327      -0.693       2.079\n",
      "x2             1.6094      0.447      3.599      0.000       0.733       2.486\n",
      "x3             2.4849      0.289      8.608      0.000       1.919       3.051\n",
      "x4             2.5649      0.277      9.248      0.000       2.021       3.109\n",
      "x5             2.8332      0.243     11.682      0.000       2.358       3.309\n",
      "x6             3.1781      0.204     15.569      0.000       2.778       3.578\n",
      "x7             3.3322      0.189     17.632      0.000       2.962       3.703\n",
      "x8             3.4340      0.180     19.120      0.000       3.082       3.786\n",
      "x9             3.5264      0.171     20.562      0.000       3.190       3.862\n",
      "x10            3.8918      0.143     27.243      0.000       3.612       4.172\n",
      "x11            3.8501      0.146     26.395      0.000       3.564       4.136\n",
      "x12            4.1431      0.126     32.885      0.000       3.896       4.390\n",
      "x13            4.3175      0.115     37.391      0.000       4.091       4.544\n",
      "x14            4.3307      0.115     37.754      0.000       4.106       4.556\n",
      "x15            4.4773      0.107     42.001      0.000       4.268       4.686\n",
      "x16            4.4886      0.106     42.346      0.000       4.281       4.696\n",
      "x17            4.5326      0.104     43.711      0.000       4.329       4.736\n",
      "x18            4.4773      0.107     42.001      0.000       4.268       4.686\n",
      "x19            4.8040      0.091     53.062      0.000       4.627       4.981\n",
      "x20            4.8283      0.089     53.982      0.000       4.653       5.004\n",
      "x21          -19.6863   1.14e+04     -0.002      0.999   -2.24e+04    2.24e+04\n",
      "x22            2.1972      0.333      6.592      0.000       1.544       2.851\n",
      "x23            2.3979      0.302      7.953      0.000       1.807       2.989\n",
      "x24            2.4849      0.289      8.608      0.000       1.919       3.051\n",
      "x25            2.3979      0.302      7.953      0.000       1.807       2.989\n",
      "x26            2.8332      0.243     11.682      0.000       2.358       3.309\n",
      "x27            3.6376      0.162     22.424      0.000       3.320       3.956\n",
      "x28            3.7612      0.152     24.664      0.000       3.462       4.060\n",
      "x29            3.9512      0.139     28.493      0.000       3.679       4.223\n",
      "x30            3.9703      0.137     28.904      0.000       3.701       4.240\n",
      "x31            3.8712      0.144     26.820      0.000       3.588       4.154\n",
      "x32            4.1589      0.125     33.271      0.000       3.914       4.404\n",
      "x33            4.2341      0.120     35.171      0.000       3.998       4.470\n",
      "x34            4.3041      0.116     37.025      0.000       4.076       4.532\n",
      "x35            4.4543      0.108     41.308      0.000       4.243       4.666\n",
      "x36            4.6634      0.097     48.013      0.000       4.473       4.854\n",
      "x37            4.4886      0.106     42.346      0.000       4.281       4.696\n",
      "x38            4.6250      0.099     46.710      0.000       4.431       4.819\n",
      "x39            4.7362      0.094     50.569      0.000       4.553       4.920\n",
      "x40            4.7875      0.091     52.444      0.000       4.609       4.966\n",
      "==============================================================================\n",
      "Residual deviance is: 5.641558699682357e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/data/miniconda3/lib/python3.9/site-packages/statsmodels/regression/_tools.py:121: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  scale = np.dot(wresid, wresid) / df_resid\n"
     ]
    }
   ],
   "source": [
    "# Saturated model CANNOT BY OBTAINED BY STATSMODELS BY DEFAULT 'CAUSE THEY PREVENT ZERO DIVISION\n",
    "\n",
    "# BUT MY WORKAROUND WHICH PROBABLY WILL NOT WORK IN COLAB AS WE DO NOT HAVE ACCESS TO MODULES IS\n",
    "# TO COMMENT OUT ROWS 1227-1229 IN MOST RECENT VERSION \n",
    "# (SEE https://github.com/statsmodels/statsmodels/blob/main/statsmodels/genmod/generalized_linear_model.py)\n",
    "\n",
    "I = np.diag(np.ones((m*n,)))\n",
    "\n",
    "\n",
    "model_s = sm.GLM(endog=Y, exog=I, family=sm.families.Poisson()).fit()\n",
    "print(model_s.summary())\n",
    "print(f'Residual deviance is: {model_s.deviance}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWfxVEHguydO"
   },
   "source": [
    "For Poisson model:\n",
    "$$D = 2 \\sum_{i=1}^n y_i log( \\frac{y_i}{\\hat{\\mu_i}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2Dm5NQ5Jr509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-572c889f4b71>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  Dev_0 = 2*np.sum(Y*np.log(Y/mu_est_0))\n",
      "<ipython-input-22-572c889f4b71>:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  Dev_0 = 2*np.sum(Y*np.log(Y/mu_est_0))\n",
      "<ipython-input-22-572c889f4b71>:6: RuntimeWarning: divide by zero encountered in log\n",
      "  Dev_1 = 2*np.sum(Y*np.log(Y/mu_est_1))\n",
      "<ipython-input-22-572c889f4b71>:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  Dev_1 = 2*np.sum(Y*np.log(Y/mu_est_1))\n"
     ]
    }
   ],
   "source": [
    "mu_est_0 = model_0.predict()\n",
    "mu_est_1 = model_1.predict()\n",
    "\n",
    "Dev_0 = 2*np.sum(Y*np.log(Y/mu_est_0))\n",
    "print(Dev_0)\n",
    "Dev_1 = 2*np.sum(Y*np.log(Y/mu_est_1))\n",
    "print(Dev_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9SuGMWFwhDM"
   },
   "source": [
    "## Anova testing \n",
    "from anova.glm?\n",
    "\n",
    "The table will optionally contain test statistics (and P values) comparing the reduction in deviance for the row to the residuals. For models with known dispersion (e.g., binomial and Poisson fits) the chi-squared test is most appropriate, and for those with dispersion estimated by moments (e.g., gaussian, quasibinomial and quasipoisson fits) the F test is most appropriate. \n",
    "\n",
    "Mallows' Cp statistic is the residual deviance plus twice the estimate of $sigma^2$ times the residual degrees of freedom, which is closely related to AIC (and a multiple of it if the dispersion is known). You can also choose \"LRT\" and \"Rao\" for likelihood ratio tests and Rao's efficient score test. The former is synonymous with \"Chisq\" (although both have an asymptotic chi-square distribution). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "u8MegJJTsqvK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anova' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c1e6e4bf8e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Chisq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Rao\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anova' is not defined"
     ]
    }
   ],
   "source": [
    "anova(model_1)\n",
    "anova(model_1, test = \"Cp\")\n",
    "anova(model_1, test = \"Chisq\")\n",
    "\n",
    "anova(model_1, model_0, test = \"Rao\")\n",
    "anova(model_1, model_0, test = \"LRT\")   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UchWeYjOxI7X"
   },
   "outputs": [],
   "source": [
    "# p-value of deviance tst\n",
    "# H0: model fit data\n",
    "p_dev <- pchisq(model_1$deviance, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "p_dev\n",
    "\n",
    "# critical value\n",
    "C_val <- qchisq(0.05, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "C_val\n",
    "\n",
    "#summary(model_1)\n",
    "#pchisq(1168 - 44, df=(39-38))\n",
    "\n",
    "anova(model_1,model_s, test = \"LRT\")   # saturated vs. final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz4Ek6Y464bE"
   },
   "source": [
    "## Rao statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrTIUoUKUKDg"
   },
   "outputs": [],
   "source": [
    "######## Rao score statistics (for Poisson GLM)\n",
    "\n",
    "score = model_1.resid_response / model_1.model.family.variance(model_1.predict())\n",
    "rao = score.T @  np.diag(model_1.model.family.variance(model_1.predict())) @ score\n",
    "print(f'rao score statistic: {rao}')\n",
    "\n",
    "# p-hodnota testu adekvatnosti modelu (pomoci Raovy statistiky)\n",
    "# H0: model dobre popisuje data\n",
    "\n",
    "print(f'p-val of rao test: {scipy.stats.chi2.sf(rao, df=model_1.df_resid)}')\n",
    "\n",
    "######  pomoci saturovaneho modelu\n",
    "model_1.model.score_test()\n",
    "#anova(model_1,model_s, test = \"Rao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.model.family.variance(model_1.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y-mu_est_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.resid_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.resid_pearson @ model_1.resid_pearson.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rao(model_1, model_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array(([1,1]))\n",
    "model_1.wald_test(R, scalar=True)\n",
    "#model_0.deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F(model_n, model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAmB4PDZJKEl"
   },
   "source": [
    "# Your turn:\n",
    "1. Generate data with followings parameters\n",
    " * $Y \\sim Poi(\\mu_i)$, where $E[Y_i] = \\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} = x_i^T \\beta \\  \\Rightarrow \\ q(\\mu_i) = \\mu_i =  x_i^T \\beta  = \\eta_i$\n",
    "* $X_{i1} \\sim N(50,10)$\n",
    "* $X_{i2} \\sim U(10,60)$\n",
    "* $X_{i3} \\sim Ber(0.45)$\n",
    "* $n = 40$\n",
    "2. Compute $\\hat{\\mu_i}$  for saturated, null,\"full\",\"best\" models.\n",
    "3. Compute Deviance, Rao, Wald statistics for your model and compare final model with the saturated and \"full\" ones.\n",
    "4. Generate 100x data for  $n \\in \\{20,40,60,80,100 \\}$ and plot $(\\hat{\\beta_i} -\\beta_i)$ vs. $(n)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O60Qhn1rV7Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3+qISYKNbOXYZbGEQmi1a",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01ZLMA_ex03.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
