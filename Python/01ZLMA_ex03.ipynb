{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Many98/GLM_R2Py/blob/main/Python/01ZLMA_ex03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-i6MbNFm4Zt"
   },
   "source": [
    "# 01ZLMA - Exercise 03\n",
    "Exercise 03 of the course 01ZLMA. \n",
    "\n",
    "## Contents\n",
    "\n",
    "* Statistical Inference\n",
    " ---\n",
    "* Testing\n",
    " ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "593Mg4ZbbeEE"
   },
   "source": [
    "#  Necessary theory recap from Lecture 04\n",
    "\n",
    "Under the conditions of regularity holds\n",
    "\n",
    "1.  $ \\ U(\\beta) \\sim N_{p}(0,I(\\beta)) \\Rightarrow  I^{-\\frac{1}{2}}(\\beta)\\, U(\\beta) {\\stackrel{D}{\\longrightarrow}} N_{p}(0, 1)$\n",
    "2. $ U(\\beta)I^{-1}(\\beta)U(\\beta)\\sim \\chi^{2}(p) \\Rightarrow U(\\beta)^T I^{-1}(\\beta)U(\\beta)  {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "3. Consistency of $\\hat{\\beta}$ and Wald statistics: \\\\\n",
    " $\\hat{\\beta}\\sim N_{p}(\\beta,I^{-1}(\\beta)) \\Rightarrow\n",
    "(\\hat{\\beta}-\\beta)^T I(\\beta)(\\hat{\\beta}-\\beta) {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2c7jDIXSGGL"
   },
   "source": [
    "Saturated and null model\n",
    "\n",
    "* Null model: $\\mu_i = \\mu, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Null Model assumes one parameter for all of the data points, which means you only estimate 1 parameter. \n",
    "* Saturated model: $Y_i = \\hat{\\mu_i}, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Saturated Model is a model that assumes each data point has its own parameters, which means you have n parameters to estimate.\n",
    "* Proposed Model:  model, where you try to explain your data points with $p$ parameters + an intercept term, so you have p+1 parameters, where $1 \\leq p \\leq n$.\n",
    "\n",
    "Questions:\n",
    "* What is the difference between null and saturated model?\n",
    "* Which model has greater log-likelihoood value?\n",
    "* Which model has the highest log-likelihood value?\n",
    "* What can you say about asymptotic distributions of $\\hat{\\beta}$ and $U(\\hat{\\beta})$ for saturated model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um9ho8cQHobx"
   },
   "source": [
    "## Let's code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-kZTsg7FZoM"
   },
   "source": [
    "Use Example 2 from the last Exercise 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n  = 20 # n observations\n",
    "m  = 2 # m parameters to estimate\n",
    "X1 = np.ones((n*m,))  # Intercept\n",
    "X2 = np.array([i for i in range(1, n+1)] * m) # Regressors\n",
    "X = np.vstack([X1, np.log(X2)]).T # design matrix\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m) # Response variable with Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jU_eFKcbWMUy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -126.23\n",
      "Date:                Thu, 01 Sep 2022   Deviance:                       32.852\n",
      "Time:                        19:43:45   Pearson chi2:                     31.3\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1190      0.124      8.997      0.000       0.875       1.363\n",
      "x1             1.2063      0.048     25.278      0.000       1.113       1.300\n",
      "==============================================================================\n",
      "estimated params are:[1.11903977 1.20626365]\n",
      "fitted values are:[  3.06191265   7.06503531  11.52197215  16.30181187  21.33707592\n",
      "  26.585716    32.01871066  37.61468394  43.35716181  49.23301614\n",
      "  55.23151218  61.34369065  67.56194848  73.87974361  80.29138079\n",
      "  86.79185227  93.37671656 100.04200456 106.78414568 113.59990876\n",
      "   3.06191265   7.06503531  11.52197215  16.30181187  21.33707592\n",
      "  26.585716    32.01871066  37.61468394  43.35716181  49.23301614\n",
      "  55.23151218  61.34369065  67.56194848  73.87974361  80.29138079\n",
      "  86.79185227  93.37671656 100.04200456 106.78414568 113.59990876]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwT0lEQVR4nO3deZzW8/rH8dfVQrIVdVBpsYtIzaGD49j37dgZCdmOnGP9WY5dsh5Ltsga5kQia5YkHCSmtIhS0qSUoiiiba7fH5/vTLdp7umee79n3s/HYx73fX+X+/vpnul73Z/t+pi7IyIiAtAg1wUQEZH8oaAgIiKVFBRERKSSgoKIiFRSUBARkUoKCiIiUklBQeoFM5toZnvmuhyZZmbvmtkZCR7rZrZFpsskhaVRrgsgUhtmNh3YCFgB/Aq8Dpzn7r/UdJ67b5f50okUPtUUpBAd5u7rAF2AIuCqHJdHpM5QUJCC5e6zCDWF7QHM7PComeinqBll24pjzWy6me0bPd/ZzErNbKGZfW9md0bbm5jZ02b2Y/Qen5rZRtG+Vmb2spnNN7OpZnZmzHtfZ2aDzOxJM1sUlaEoXrmjZptzzWxKdHxvM9vczD6KyjTIzNaIOf7M6JrzozK0itm3n5lNMrOfzew+wKpc63Qz+9LMFpjZm2bWLsWPXeo4BQUpWGa2KXAw8JmZbQUMBC4AWgJDgVdib64x+gJ93X09YHNgULS9B7A+sCmwIXAO8Fu07xlgJtAKOAa4ycz2jnnPw6NjmgEvA/etpvgHAF2BbsClQH/g5Oja2wMnRv/GvYGbgeOATYCy6DqYWQvgBUJNqQXwNbBbzOdzBPBv4KjoM/lf9BmJxKWgIIXoRTP7CfgAeA+4CTgeeM3dh7n7MuA/wFrArtWcvwzYwsxauPsv7v5xzPYNgS3cfYW7j3b3hVHw2Q24zN1/d/exwCPAKTHv+YG7D3X3FcBTwI6r+Tfc5u4L3X0i8DnwlrtPc/efCbWfnaLjioHH3H2Muy8BrgD+YmbtCQFxorsPjv7NdwNzYq5xDnCzu3/p7sujz6mzagtSEwUFKURHunszd2/n7ue6+2+Eb/BlFQe4eznwLdC6mvN7AlsBk6ImokOj7U8BbwLPmNl3ZnabmTWO3nu+uy+KeY+yKu8dezNeDDQxs5oGcnwf8/y3al6vEz2v+u/6Bfgxunar6N9Ysc9jXwPtgL5RU9hPwHxC81J1n4kIoKAgdcd3hJsgAGZmhKaYWVUPdPcp7n4i8CfgVmCwma3t7svc/Xp370ioYRxKqA18B2xgZuvGvE3b6t47A6r+u9Ym1GZmAbMJ/8aKfRb7mhAgzo4CaMXPWu7+URbKLQVKQUHqikHAIWa2T/Tt/mJgCbDKDdDMTjazllFt4qdoc7mZ7WVmncysIbCQ0JxU7u7fRu9zc9QZvQOhtvF05v9ZDAROM7POZrYmoQlolLtPB14DtjOzo6Jayb+AjWPOfRC4wsy2AzCz9c3s2CyUWQqYgoLUCe4+mdBRey/wA3AYYejq0moOPxCYaGa/EDqdT4iaoDYGBhMCwpeE/oqnonNOBNoTvrkPAa5197cz9g+KRNe4GnieUDPYHDgh2vcDcCxwC6FJaUvgw5hzhxBqQs+Y2UJC38VBmS6zFDbTIjsiIlJBNQUREamkoCAiIpUUFEREpJKCgoiIVCroLKktWrTw9u3b57oYIiIFZfTo0T+4e8vq9hV0UGjfvj2lpaW5LoaISEExs7J4+9R8JCIilRQURESkkoKCiIhUUlAQEZFKCgoiIlJJQUFEpJCUlED79tCgQXgsKUnr2xf0kFQRkXqlpATOOgsWLw6vy8rCa4Di4rRcQjUFEZFCceWVKwNChcWLw/Y0UVAQESkUM2bUbnsSFBRERApF27a1254EBQURkULRpw80bfrHbU2bhu1poqAgIlIoiouhf39o1w7MwmP//mnrZAaNPhIRKSzFxWkNAlWppiAiIpUUFEREpJKCgoiIVMpYUDCzx8xsrpl9HrPtdjObZGbjzWyImTWL2XeFmU01s8lmdkCmyiUiIvFlsqbwBHBglW3DgO3dfQfgK+AKADPrCJwAbBed84CZNcxg2UREpBoZCwru/j4wv8q2t9x9efTyY6BN9PwI4Bl3X+Lu3wBTgZ0zVTYRkYKV4YR4uexTOB14PXreGvg2Zt/MaNsqzOwsMys1s9J58+ZluIgiInmkIiFeWRm4r0yIl8bAkJOgYGZXAsuBWv9L3L2/uxe5e1HLli3TXzgRkXyVhYR4WZ+8ZmanAocC+7i7R5tnAZvGHNYm2iYiIhXqWkI8MzsQuBQ43N1jw93LwAlmtqaZdQC2BD7JZtlERPJeISfEM7OBwEhgazObaWY9gfuAdYFhZjbWzB4EcPeJwCDgC+ANoJe7r8hU2UREClIWEuLZyhacwlNUVOSlpaW5LoaISPaUlIQ+hBkzQg2hT59a50Iys9HuXlTdPiXEExEpJEqIJyIi2aKgICIilRQURESyrLwcBgyApUtzXZJVKSiIiGTRd9/BAQfAqafCwIG5Ls2qFBRERLLkhRegUyf46CN46CE45ZRcl2hVCgoiIhn2yy/QsyccfTR06ACffRZSFpnlumSrUlAQEcmgTz6BnXaCxx+HK64ItYSttsp1qeJTUBARyYDly6F3b9h119Ch/O67cNNNsMYauS5ZzTR5TUQkzb75Brp3hw8/hJNOgvvvh2bNcl2qxCgoiIikiTs8/TT06hX6C55+OqOTjzNCzUciImnw00+hVnDKKbDjjjBuXOEFBFBQEBFJ2XvvwQ47wODBIT/du++GlTILkYKCiEiSli4NI4r22guaNAkji/79b2jYMNclS576FEREkjBpUmgeGjMGzjwT7rwT1lkn16VKnWoKIiK14B5GE3XpAmVlMGQI9O9fy4BQUhLalxo0CI8ltV6uPmNUUxARSdCcOXD66fD663DggfDYY7DJJrV8k5KSMJ15cbQicVlZeA150TOtmoKISAKGDIHtt4cRI+C++2Do0CQCAoRV0xYv/uO2xYvD9jygoCAiUoNFi0LeoqOOgnbtQt6iinkISZkxo3bbs0xBQUQkjo8+gs6d4YknwqiikSNhm21SfNO2bWu3PcsUFEREqli2DK6+Gv7617AgznvvhfkHaclb1KcPNG78x22NG4fteUBBQUQKVwZG8UyeHJLY3XhjmJ08bhzsvnvKb/tHVdue8iiHtoKCiBSmilE8ZWVhnGjFKJ4kA4M79OsX0lxPmxZmJz/+OKy3XprLfeWVq67DuXRp3e9oNrPHzGyumX0es20DMxtmZlOix+bRdjOze8xsqpmNN7MumSqXiNQRaRzFM2cOHHoonHsu7LEHTJgQFsTJiHrc0fwEcGCVbZcDw919S2B49BrgIGDL6OcsoF8GyyUidUGabq4vvRSWyHznHbj33jAHoVWrNJQvnvra0ezu7wPzq2w+AhgQPR8AHBmz/UkPPgaamVkyI4BFpL5I8ea6aBGccQYceSRsumlIV3HeeVlo3u/TB5o2/eO2pk3rbUfzRu4+O3o+B9goet4a+DbmuJnRtlWY2VlmVmpmpfPmzctcSUUkv6Vwc/3gg5DeumKJzI8/hm23zVA5qyouDnkx2rULEahdu/A6D2YzQw47mt3dAU/ivP7uXuTuRS1btsxAyUSkICRxc12yBC6/PPQbmMH77+doicziYpg+PYx3nT49bwICZD/30fdmtom7z46ah+ZG22cBm8Yc1ybaJiISX3FxwjfUCRPg5JNh/PiQ1fSOO2DddTNcvgKU7ZrCy0CP6HkP4KWY7adEo5C6AT/HNDOJiCRtxQr4z3+gqCiMMnrllVChUECoXsZqCmY2ENgTaGFmM4FrgVuAQWbWEygDjosOHwocDEwFFgOnZapcIlJ/TJ8OPXqEZqK//x0eegjU6lyzTI4+OtHdN3H3xu7ext0fdfcf3X0fd9/S3fd19/nRse7uvdx9c3fv5O6lmSqXiNQhcWY0u4d8RTvsEBLYPfEEPP98lYCQymzoPF4PIVVaT0FEClOcdQnmLVyTs4cdw5AhoUN5wIBq1ktOZU2DPF8PIVUWBgEVpqKiIi8tVaVCpF5q3z7ckGO8yiH0bPA4PzVqSZ8+cOGFcdZLruZcIIxgmj691tdN+Nw8YWaj3b2oun3KfSQihSlm5vIi1uFM+nMYr7JJ+SxKS+GSS+IEhCrnJrQ9XecWAAUFESlM0czlD9mVzozlUXpyGbcwqu1xdOqU2LkJb0/XuQVAQUFECtKS627mskZ3sAfv4xjvswe3NO3Nmjddu/qTU0k1kedpKlKloCAiBWfsWCi640RuW34RPdd5lnF0Zvd2MxNPF5FKqok8T1ORKnU0i0jBWL4cbr0VrrsuDC995BE4+OBcl6rw1NTRrCGpIlIQJk8OE9FGjYLjj4f774cNN8x1qeoeNR+JSF4rL4d77gkrok2ZAs88E35yGhA0eU1EJPtmzIDTTgsL4Bx8cGgu2iTXK63U8clrq60pmNluZrZ29PxkM7vTzNplvmgiUl9VpKno1Ak++ST04776ah4EBEjrMqD5KJHmo37AYjPbEbgY+Bp4MqOlEpH6o0pTzPcPPM+RR4YaQufOK1NdZ3xFtERp8hrLowVxjgDuc/f7ASWdFZHUVTTFlJWBO8+XdWX7Xnvw5usruOMOGDECOnTIdSGr0OQ1FpnZFUB34DUzawA0zmyxRKReiJpiFtCMk3mKY3ietsxgTIsDuOiiUHnIO5q8xvHAEuB0d59DWBXt9oyWSkTqhxkzeIMD6MQEnuEEruU6PqYbHee8k+uSxVfHJ6+tdvSRu88xs+eBLaNNPwBDMloqEanzFi2Ci9d+mod/OYlt+YIXOZIiRoedbfN8LEstlgEtNImMPjoTGAw8FG1qDbyYwTKJSB33zjthZNEjv57I/zW6izF0WRkQ6lBTTCFKpPmoF7AbsBDA3acAf8pkoUSkbvr1VzjvPNhnH1hjDfjgA+O2J/5Ek3Yb18mmmEKUyOS1Je6+1KLxYGbWCCjchEkikhMffACnngpffw3/+hfcfHPUX7tr3W2KKUSJ1BTeM7N/A2uZ2X7Ac8ArmS2WiNQVv/0GF18clsYsL4d334W+fVcdwCP5IZGgcDkwD5gAnA0MBa7KZKFEpG4YNQq6dIE774Szzw4T0f72t1yXSmqSyOijcuBh4GEz2wBo44Wcb1tEMm7JErj++pDmunVreOst2G+/XJdKEpHI6KN3zWy9KCCMJgSHu1K5qJldaGYTzexzMxtoZk3MrIOZjTKzqWb2rJmtkco1RCQ3PvsM/vzn0Gdw6qkwYYICQiFJpPlofXdfCBwFPOnuuwD7JHtBM2sN/AsocvftgYbACcCtwF3uvgWwAOiZ7DVEJPuWLQu1g513hh9+CAnsHn0U1l8/1yWT2kgkKDQys02A44BX03TdRoSO60ZAU2A2sDdhPgTAAODINF1LRDJswgTo1i2siHb88fD553DIIbkulSQjkaBwA/AmMNXdPzWzzYApyV7Q3WcB/wFmEILBz4RmqZ/cfXl02EzCJDkRyWPLlsGNN0LXrvDtt/D88/D007DBBrkumSQrkY7m5wjDUCteTwOOTvaCZtackHG1A/BT9N4H1uL8s4CzANrWkayEIoVowoTQZzBmTKgd3HcftGiR61JJqlYbFMysCaF9fzugScV2dz89yWvuC3zj7vOi93+BMGO6mZk1imoLbYBZ1Z3s7v2B/gBFRUUaBSWSZcuWhVFFN9wAzZvD4MFwdNJfEyXfJNJ89BSwMXAA8B7hhr0ohWvOALqZWVML06T3Ab4ARgDHRMf0AF5K4RoikgHjx4e+g6uvDoFg4kQFhLomkaCwhbtfDfzq7gOAQ4Bdkr2gu48idCiPIUyIa0D45n8ZcJGZTQU2BB5N9hoikl7LlkHv3lBUBDNnhr6DgQOj5qI6vIh9fZRIUFgWPf5kZtsD65NiQjx3v9bdt3H37d29u7svcfdp7r6zu2/h7se6+5JUriEi6VFRO7jmmpW1g6OOinZWWTmtchH72gQGBZW8kkhQ6B91Dl8FvExo6rkto6USkZyrsXZQIdVF7NMRVCStrJAzVhQVFXlpaWmuiyFS+EpKwo18xgxo25bxZ9/Pqc8dwmefwQknwL33xhlZ1KBBuJlXZRay361O+/YhEFTVrh1Mn17Lf4QkysxGu3tRdfsSSXNxk5k1i3nd3MxuTGP5RCSXYr6tL/OG9C7rTtG/92PW179VXzuIleoi9jNm1G67ZFwizUcHuftPFS/cfQFwcMZKJCLZFTUBjacTuzCKa+jNMQxm4nq7ruw7iCfVRexTDSqSdokEhYZmtmbFCzNbC1izhuNFpIAsLZvNtVxHV0Yzi9a8wN/5L8W0mDVu9ScXF0OPHtCwYXjdsGF4neiiOakGFUm7RIJCCTDczHqaWU9gGCE3kYgUuNJS6Np4HDdwLScykC/oyN8rlmBP5Nt6SQkMGAArVoTXK1aE14l2FBcXh+U327XTcpx5IqGOZjM7kDATGWCYu7+Z0VIlSB3NIsn57beQ0fT222Hj9Rfz0OLuHLrkhZUHNG2a2M1ZHcUFKaWOZgB3f8PdL4l+8iIgiEhyPvwQdtoppKo4/XSYOK0phz56VHLf1gu5o1jzI6q12txHIlI3/Ppr6FO+557QMvSH1dCKi5NrsmnbtvqaQr53FFeMuKqYY1ExPwLqfdNVQjUFESlsI0ZAp07Qty/06hXWO0jLamiF2lGc6qS7OixuUDCz4dHjrdkrjoik08KF8I9/wN57h4FB770XJqKts06aLlCoHcWF3OyVYTU1H21iZrsCh5vZM4DF7nT3MRktmYik5I03QovIrFlwySWhY7nql/q0SLbpKZcKtdkrC2oKCtcAVxNSZd9ZZZ8Tls8UkTyzYAFcdBE88QR07AgffQS7JJ3XuI7q0+ePfQpQGM1eWRA3KLj7YGCwmV3t7r2zWCYRSdKLL4bmonnzQvP41VfDmppquqqKmk1Mvif69Cm8Gk8GrLaj2d17m9nhZvaf6OfQbBRMRBL3/fdw3HHw97/DRhvBp5+GtZMTDgj1cXhmcXGYS1FeHh4VEIDEEuLdDJxPSJn9BXC+md2U6YKJyOq5h2aibbeFl18OX3Y//TTMQ0iY0ldLjNXOaDaz8UBndy+PXjcEPnP3HbJQvhppRrPUZ9Onh3v3sGGw++7w8MOwzTZJvJFmJdc7Kc9oBprFPF8/5RKJSNJWrAjzDbbbDkaOhPvvD0NNkwoIoOGZ8geJzGi+GfjMzEYQhqXuAVye0VKJSLUmToSePWHUKDj4YOjXLw2jKDU8U2Ik0tE8EOgGvAA8D/zF3Z/NdMFEZKWlS8M8g512gqlTQ3P/q6+m6b5dqLOSJSMSyn3k7rMJ6zOLSJaNGgVnnBFSU5x0Etx9N7RsmcYLaHimxFBCPJE89euvYZ7B3XdD69ahZnDIIRm6WCHOSpaMUFAQyUNvvx1GFn3zDZx7Ltx8M6y3Xq5LJfVBjX0KZtbQzCal+6Jm1szMBpvZJDP70sz+YmYbmNkwM5sSPTZP93VF8t38+WGNg/32g8aN4f33w+iihALCuedCo0YhMV2jRuG1SC3VGBTcfQUw2czSPQyhL/CGu28D7Ah8SRjRNNzdtwSGoxFOUo+4w8CBYVjpk0/CFVfAuHHw178m+AbnnhuGIsUui9mvnwKD1Foik9feB3YCPgF+rdju7ocndUGz9YGxwGYec3Ezmwzs6e6zzWwT4F1337qm99LkNakLpk8P9+7XX4c//xkeeQR2qO3U0EaNVgaEWA0bwvLl6Sim1CE1TV5LpE/h6jSXpwMwD3jczHYERhPSaGwUjXICmANsVN3JZnYWcBZAW42jlgK2fHlY2+Cqq0KLT9++0Kv5f2l4+L9rPwqouoBQ03aROBKZp/AeMB1oHD3/FEhlLYVGQBegn7vvRKh9/KGpKKpBVFuFcff+7l7k7kUt0zouTyR7PvsMunULKa732gu++AL+tWEJDc85M7kcRA0b1m67SByJJMQ7ExgMPBRtag28mMI1ZwIz3X1U9HowIUh8HzUbET3OTeEaInlp8WK49NLQTDRzJjz7LLzySjQJLZUlIivWF050u0gcieQ+6gXsBiwEcPcpwJ+SvaC7zwG+NbOK/oJ9CNlXXwZ6RNt6AC8lew2RfDRsGGy/Pdx+O5x2Gnz5ZUh3bRVrGqaSg+iBB8JCChU1g4YNw+sHHkhL2aX+SCQoLHH3pRUvzKwRcZp2auGfQElFBlbgJuAWYD8zmwLsG70Wyb40ry3www9wyimw//5hmOm774aMps2rDrqO10eWaN/ZAw+Ejgr38KiAIElIpKP5PTP7N7CWme0HnAu8kspF3X0sUF3P9z6pvK9IyirWFqhoxqlo14daz/h1h6efhgsvhJ9/Dh3KV14JTZrEOUFLREoeSKSmcDlhtNAE4GxgKHBVJgslkjOptOvHmDYNDjgg1BC22ip0LPfuXUNAgBB0+vcP6xiYhcf+/ZV+QrJqtTUFdy83swHAKEKz0WRf3eQGkUKV4toCy5bBnXeGjKaNGsF994Wm/QaJrlwikmOrDQpmdgjwIPA1YT2FDmZ2tru/nunCiWRdCmsLfPQRnH12yGZ65JFhDkKbNrW4dhqbrkSSlcj3lzuAvdx9T3f/G7AXcFdmiyWSI0msLbBgQQgGu+0W+g5eegmGDKllQIC0NV2JpCKRoLDI3afGvJ4GLMpQeURyqxbt+rH5ih55JExE++ILODypBDBoWUzJC3Gbj8zsqOhpqZkNBQYR+hSOJcxqFqmbElhb4OuvQ1/BsGFhItobb4RV0VKiZTElD9RUUzgs+mkCfA/8DdiTMBJprYyXTCQPLV0KN90UJqF9/HHoNxg5Mg0BAbQspuSFuDUFdz8tmwURyXf/+x+cc05oIjrmmJDArlWrag4sKUluaUstiyl5IJHRRx0IM5Dbxx6fbOpskUIzfz5cdlnoN2jXbjXLYqY6gkjLYkqOJbKewjjgUcLktfKK7VHG1JzSegqSSe7hHn/RRSEwXHwxXHMNrL12DSe1b199v0C7dmHhBJE8kOp6Cr+7+z1pLpNIXvvqq7DwzfDhIcX1228nuPCNRhBJgUtkSGpfM7s2Wke5S8VPxksmkgO//RZqA506QWlpWNHyww9rsRJaqkntRHIskZpCJ6A7sDcrm488ei1SZwwdCuedB998AyefHFJcb7xxLd9ESe2kwCUSFI4lrKe8dLVHihSgb7+F888Ps5C33RZGjIA990zyzYqLQ9Wif/+wFGbDhtCjhzqPpWAk0nz0OdAsw+UQybply0JtYNttw+Szm2+GsWNTCAgQeqYHDFi5NvKKFeF1imsyiGRLIjWFZsAkM/sUWFKxUUNSpZC9/37oSJ44EY44Au6+OwwcSllN+YtUW5ACkEhQuDbjpRDJkrlzwxrJAwaEUaIvvwyHHZbGC2j0kRS4RNZTyPl8BJFUrVgRlsC84gr49dfweNVVq2aVSJnyF0mBW22fgpktMrOF0c/vZrbCzBZmo3Ai6TBmDOy6a0hgt9NOMG5cyF+U9oAAyl8kBW+1QcHd13X39dx9PUIivKMBrQguee/nn+Gf/wxZTMvKQl/v8OGhYzljtKSmFLjVprmo9iSzz9w9HXkhU6I0F1Kd8nJ46qnQd/DDD6FDuXdvaNYs1yUTyQ8ppbmIWVcBQs2iCPg9TWUTSavPPgsT0D76CHbZJUxI69o116USKRyJjD6KHZuxHJgOHJGR0ogkacGC0HH84IOw4Ybw2GNhzliDRGbiiEilREYfZWRdBTNrCJQCs9z90ChF9zPAhsBooLtmUcvqlJfD44/D5ZeHTKa9esH110Pz5rkumUhhqmk5zmtqOM/dvXeK1z4f+BJYL3p9K3CXuz9jZg8CPYF+KV5D6rDS0hAEPvkEdt8d7rsPdtwx16USKWw1Va5/reYHws36slQuamZtgEOAR6LXRkiwNzg6ZABwZCrXkLrrxx/h7LNh553DnLCnngozlBUQRFIXNyi4+x0VP0B/wnDU0whNPJuleN27gUtZmXV1Q+And18evZ4JtK7uRDM7y8xKzax03rx5KRZDCsmKFfDQQ7DVVvDoo3DBBTB5cshoapbGC5WUhJwXDRqER+Utknqkxm44M9vAzG4ExhOamrq4+2XuPjfZC5rZocBcdx+dzPnu3t/di9y9qGXLlskWQwrMqFFhNNE554S1DsaOhTvvhPXWW+2ptVOxnGZZWVh6rWI5TQUGqSfiBgUzux34FFgEdHL369x9QRquuRtwuJlNJ9Q69gb6As3MrKKPow0wKw3XkkJWUsK8TbvQ0x6jWzeYPW0xAweG1Nbbb5+ha9aU0E6kHqippnAx0Aq4CvguJtXFolTSXLj7Fe7ext3bAycA77h7MTACOCY6rAfwUrLXkMK3bMB/ufu0cWw58x2epDv/x21M+r0DJ6woSW9TUVVKaCf1XE19Cg3cfa3YNBfRz7pRyot0uwy4yMymEvoYHs3ANaQAvPUW7Hjmn7lw2W3swijGswO3cRnr/jY389/YtZym1HM5ndrj7u+6+6HR82nuvrO7b+Hux7r7ktWdL3XL11+HtQ0OOACWLjNe5jDe4EC2ZdLKgzL9jV0J7aSe03xPyblFi0Iq644d4Z134JZbYGLbgzmMV1mlpSjT39iV0E7quUTSXIhkRHl5GNRz2WUwezacckpYErNVK6DNtWHUT2ynb7a+sRcXKwhIvaWaguTEJ5/AbruFQNCmDYwcGVZDa9UqOkDf2EVyQkFBsmrOHDjttDDn4JtvQt6ijz+Gbt2qObi4GKZPD1WK6dNrFxA0AU0kKWo+kqxYuhT69g3rGvz+O/zf/4WspmmffAYrJ6BVND1VTEAD1TREVkM1Bckod3jttTDZ7NJLYY894PPP4bbbMhQQQBPQRFKgoCAZM2FCGF566KGhFWfoUHj11ZC7KKM0AU0kaQoKknbffx+ymHbuHNJb3303jB8PBx2UpQJoAppI0hQUJG1+/z3MMdhyy7Dy2T//CVOnwvnnwxprZLEgffpA48Z/3Na4sSagiSRAHc2SMncYNCjMNygrg8MPD30GW2+dw0JVTZCU0YRJInWHagqSklGjwnyDE06AZs3g7bfhpZdiAkIqQ0OTPffKK8Nwp1hLl6qjWSQBqilIUmbMCKkp/vtf2HjjsOhNjx7QsGHMQakMDU3lXHU0iyTN3D3XZUhaUVGRl5aW5roY9cqiRXDrrXDHHeH1xReHZqN1163m4Pbtw828qnbtwmS0muTqXJF6wMxGu3tRdfvUfCQJWbEi1Aa22ir01x59dFgK88Yb4wQESO0beyrnKtOpSNIUFGS1hg2Drl3hjDNgs81CWoqnn05ghGcqQ0NTOVd5k0SSpqAgcY0dGyaf7b8//PwzPPssfPBByFuUkFSGhqb6bT+VvEki9ZiCgqyirCxkL+3SJUw+u+vkUiaVb8VxJzTAOrSv3QiiZIeG6tu+SE6oo1kqLVgAN90E994b7sMXXACXdRhEswtPW3Vdg0Ru0OrwFclLNXU0KygIv/8O990XWmZ+/hlOPRWuvx423ZTUbuwNGoSZbVWZhWYdEckJjT6q7+JMAisvDx3GW28dUln/5S+hH+Gxx6KAAKmNAlIOIpGCo6BQ11VMAisrC9/ao0lgwy4fTteu0L07tGgBw4eHLKY77FDl/A02qP59422PpaGhIgVHQaGuq7K2wFh2ZP/FQ9j/1n346acwI/nTT2HvvTNwbXUWixScrAcFM9vUzEaY2RdmNtHMzo+2b2Bmw8xsSvTYPNtlq5OiZp7ptOMUBtCFMYymK3dyEZMmwYknhlaluObPr932qjQ0VKSg5KKmsBy42N07At2AXmbWEbgcGO7uWwLDo9eSojmtu/JP7mErvmIQx3Ept/E1m3NhuxdYc80E3kD9AiL1StaDgrvPdvcx0fNFwJdAa+AIYEB02ADgyGyXrS6ZPz8krNts7kj68Q9O43GmsgW3cAXNmi5LvF1f/QIi9UpO+xTMrD2wEzAK2MjdZ0e75gAbxTnnLDMrNbPSefPmZaegBeSXX0I+og4dQuK6o45txKT/vMZD7W6mjX1X+3Z99QuI1Cs5Cwpmtg7wPHCBuy+M3edh8kS1Eyjcvb+7F7l7UcuWLbNQ0sLw++/Qt2/ITXT11bDXXjBuXBhyusXGv6T25uoXEKk3chIUzKwxISCUuPsL0ebvzWyTaP8mwNxclK3QLF++MnvpBReEIaUjR8KLL0KnTsQdklqrVBUiUm/kYvSRAY8CX7r7nTG7XgZ6RM97AC9lu2yFpLwcnnkGOnYM2UtbtQqrnr39NnTrFnNglSGpQHitVchEpBq5qCnsBnQH9jazsdHPwcAtwH5mNgXYN3otVbjDq6/CTjuF4aRrrhmWvxw5EvbZp5oTtAqZiNRC1pfjdPcPgHipMqu7rQkhGIwYAVddFQLA5puHFqDjj6+yBGZVbdtWn7tIQ0pFpBqa0Zzn3EMKij32CDWBGTPgoYfgyy/hpJNWExBAQ0pFpFYUFPKUe1jx7K9/hX33hW8mLube5tcwddZanHVTexoPSrCjWENKRaQWst58JDVzh7feCqmrR46ENm3g/h6fcPqgA2ny24JwUMUIIkjs5l5crCAgIglRTSFPuMMbb4T01QceCDNnwgMPwNSpcO67x60MCBU0gkhEMkBBIcfcQ8rqbt3goINg9mx48EGYMgX+8Y8wukgjiEQkWxQUcqRiaOkuu8Ahh8DcuaGpf8oUOPts/pisTknpRCRLFBSyzB1eeQX+/Gc47DCYNw8eeQS++grOPBPWWKOakzSCSESyREEhS5YvDzOQu3aFww+HBQtCeoqvvoKePaFx4xpO1ggiEckSjT7KsMWL4fHH4Y474JtvwnrIjz8e7uc1BoKqNIJIRLJANYUM+fFHuOGG8KX+vPNgo41gyBD44gs49dRaBgQI05fbtw/LpLVvr4R2IpIRCgppVlYG558f+oCvvTaMKnr/ffjoIzjy1xIabNa+9jd2ZToVkSyxsHRBYSoqKvLS0tJcFwOA8ePhtttCv4FZaOm55BLYfvvogIobe2zG0qZNE+sbaN+++vxF7dqF9Q1ERGrBzEa7e1G1+xQUkucO770XVjh74w1YZ51w37/gAth00yoHp3Jjb9AgXKwqs5BDW0SkFmoKCupoTsKKFWERm1tvhU8/hZYtwxKY554LzZvHOSmVCWjKdCoiWaI+hVr46Se4+27YZhs45hiYPx/69Qv36yuvrCEgQGoT0DRPQUSyREEhAWPHhollrVrBhRdCixYwaBBMngznnANrrZXAm6RyY9c8BRHJEjUfxbFkCTz3XEhKN3JkuPEXF4d8RF26JPGGFTfwK68MTUZt24aAkOiNXfMURCQLVFOooqwMrrgidBR37w4//AB33QWzZsHDD0OXL1OYL1BcHDqVy8vDo27yIpJnVFMg3KOHDYP774fXXgvbDjsMevUKq501qAidVYeV1nZdAxGRPFevh6QuWBBSTvTrF9YtaNky9B2cfXac/l/NFxCROqCmIan1svlo0qSQhK51a7j44pCCoqQEvv02NPPHHRCU6roGSlUhInmuXjYfTZsWZh537x46jjt3TvDEDTYISY2q2746anoSkQJQL5uPysth4UJo1qyWJ7ZoUX1Q2HDD0CNdEzU9iUieKKjmIzM70Mwmm9lUM7s8E9do0CCJgABhtlpttsfSkpoiUgDyKiiYWUPgfuAgoCNwopl1zG2pYqQyK1lLaopIAciroADsDEx192nuvhR4Bjgix2VaKZVZyUpVISIFIN+CQmvg25jXM6NtlczsLDMrNbPSefPmZbVwKaWbUKoKESkAedXRbGbHAAe6+xnR6+7ALu5+XnXH5zp1tohIISqkjuZZQOxKBG2ibSIikgX5FhQ+BbY0sw5mtgZwAvByjsskIlJv5NXkNXdfbmbnAW8CDYHH3H1ijoslIlJv5FVQAHD3ocDQXJdDRKQ+yrfmIxERyaG8Gn1UW2Y2D6gmd0RCWgCryU2RE/laLsjfsqlctaNy1U5dLFc7d29Z3Y6CDgqpMLPSeEOycilfywX5WzaVq3ZUrtqpb+VS85GIiFRSUBARkUr1OSj0z3UB4sjXckH+lk3lqh2Vq3bqVbnqbZ+CiIisqj7XFEREpAoFBRERqVTng8LqVnIzszXN7Nlo/ygza5+FMm1qZiPM7Aszm2hm51dzzJ5m9rOZjY1+rsl0uaLrTjezCdE1V0lBa8E90ec13sy6ZKFMW8d8DmPNbKGZXVDlmKx9Xmb2mJnNNbPPY7ZtYGbDzGxK9Ng8zrk9omOmmFmPLJTrdjObFP2uhphZszjn1vh7z0C5rjOzWTG/r4PjnJuxlRjjlOvZmDJNN7Oxcc7NyOcV796Q1b8vd6+zP4T8SV8DmwFrAOOAjlWOORd4MHp+AvBsFsq1CdAler4u8FU15doTeDUHn9l0oEUN+w8GXgcM6AaMysHvdA5h8k1OPi9gD6AL8HnMttuAy6PnlwO3VnPeBsC06LF59Lx5hsu1P9Aoen5rdeVK5PeegXJdB1ySwO+6xv+/6S5Xlf13ANdk8/OKd2/I5t9XXa8pJLKS2xHAgOj5YGAfM7NMFsrdZ7v7mOj5IuBLqiwmlMeOAJ704GOgmZltksXr7wN87e7JzmRPmbu/D1RdmDv272gAcGQ1px4ADHP3+e6+ABgGHJjJcrn7W+6+PHr5MSEdfVbF+bwSkdGVGGsqV3QPOA4YmK7rJVimePeGrP191fWgsNqV3GKPif7z/AxsmJXSAVFz1U7AqGp2/8XMxpnZ62a2XZaK5MBbZjbazM6qZn8in2kmnUD8/6i5+LwqbOTus6Pnc4CNqjkm15/d6YRaXnVW93vPhPOiZq3H4jSH5PLz+ivwvbtPibM/459XlXtD1v6+6npQyGtmtg7wPHCBuy+ssnsMoYlkR+Be4MUsFWt3d+8CHAT0MrM9snTd1bKwxsbhwHPV7M7V57UKD3X5vBrrbWZXAsuBkjiHZPv33g/YHOgMzCY01eSTE6m5lpDRz6ume0Om/77qelBIZCW3ymPMrBGwPvBjpgtmZo0Jv/QSd3+h6n53X+juv0TPhwKNzaxFpsvl7rOix7nAEEIVPlYuV8c7CBjj7t9X3ZGrzyvG9xXNaNHj3GqOyclnZ2anAocCxdENZRUJ/N7Tyt2/d/cV7l4OPBznern6vBoBRwHPxjsmk59XnHtD1v6+6npQSGQlt5eBil76Y4B34v3HSZeovfJR4Et3vzPOMRtX9G2Y2c6E31VGg5WZrW1m61Y8J3RSfl7lsJeBUyzoBvwcU63NtLjf3nLxeVUR+3fUA3ipmmPeBPY3s+ZRc8n+0baMMbMDgUuBw919cZxjEvm9p7tcsf1Qf49zvVytxLgvMMndZ1a3M5OfVw33huz9faW79zzffgijZb4ijGK4Mtp2A+E/CUATQnPEVOATYLMslGl3QvVvPDA2+jkYOAc4JzrmPGAiYcTFx8CuWSjXZtH1xkXXrvi8YstlwP3R5zkBKMrS73Ftwk1+/ZhtOfm8CIFpNrCM0G7bk9APNRyYArwNbBAdWwQ8EnPu6dHf2lTgtCyUayqhnbni76xipF0rYGhNv/cMl+up6O9nPOGGt0nVckWvV/n/m8lyRdufqPi7ijk2K59XDfeGrP19Kc2FiIhUquvNRyIiUgsKCiIiUklBQUREKikoiIhIJQUFERGppKAgdV40p+IDMzsoZtuxZvZGGq+xvpk9GWXz/NrMSuJlskzw/S4ws6bpKp9IohQUpM7zMO76HOBOM2sSpRC4CeiVzPtFM16rehSY5u5buPvmhHHiTyRZZIALgFoFBTNrmML1RAAFBakn3P1z4BXgMuAa4GngSjP7xMw+M7MjICQhM7P/mdmY6GfXaPue0faXgS9i39vMtgC6Ar1jNt8A7GhhLYg9zezVmOPvi1JPYGb7RNefECWGW9PM/kWYLDXCzEZEx+1vZiOjMj0XBbaKvP63mtkY4Nj0f3JS3ygoSH1yPXASIYdSE0JKk52BvYDbo5QFc4H9PCQ7Ox64J+b8LsD57r5VlfftCIx19xUVG6LnnwHbxiuMmTUh1CaOd/dOQCPgH+5+D/AdsJe77xXlcLoK2DcqVylwUcxb/ejuXdz9mdp9HCKrqq4aLFInufuvZvYs8AshV/5hZnZJtLsJ0JZwM77PzDoDK4DYAPCJu3+TxiJtDXzj7l9FrwcQmrTurnJcN0Lg+TBK77QGMDJmf9zEbSK1paAg9U159GPA0e4+OXanmV0HfA/sSKhJ/x6z+9c47/kF0NnMGnjI+omZNYjeYwwh2MTWypvUssxGWDzlxDj745VLpNbUfCT11ZvAP2Myq+4UbV8fmB3d3LsTloSskbtPJTQVXRWz+SpguLvPAMqAjlF/QTPC6nEAk4H2UZ8E0fXei54vIizHCCHB324Vx0VZOqs2YYmkhYKC1Fe9gcbAeDObyMpO4geAHmY2DtiGxL+Fn05I8/y1mc0jNPmcA+Du3wKDCOmVBxECCO7+O3Aa8JyZTSDUYB6M3q8/8IaZjXD3ecCpwEAzG09oOtom2X+4SE2UJVUkzcxsa+A14F8eFvwRKRgKCiIiUknNRyIiUklBQUREKikoiIhIJQUFERGppKAgIiKVFBRERKTS/wPB0QQd6o5ONwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to create models we can use standard api or formula (r-like) api in statsmodels\n",
    "# formula api requires dataset (pandas) and formula\n",
    "d = pd.DataFrame(data={'Y': Y, 'X1': X1, 'X2':X2})\n",
    "#model = smf.glm(formula='Y~np.log(X2)', data=d, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# standard api requires specifying endog (response) and exog (explanatory) design matrices\n",
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "beta_e = model.params; print(f'estimated params are:{beta_e}')\n",
    "y_hat = model.predict(); print(f'fitted values are:{y_hat}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2, Y, color='red', marker='o')\n",
    "ax.plot(np.unique(y_hat), color='blue')\n",
    "ax.set_title('Poisson model')\n",
    "ax.set_xlabel('Year Quoter')\n",
    "ax.set_ylabel('Number of cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N8x-oi3HAKK"
   },
   "source": [
    "Repetition using custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calcualate weights W\n",
    "def calc_W_inv(X, beta):\n",
    "    return np.diag(np.exp(X @ beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xcA9wuh1WMtL"
   },
   "outputs": [],
   "source": [
    "# function to calcualate weights Z\n",
    "def calc_Z(X,Y,beta):\n",
    "    return X@beta + (Y - np.exp(X@beta)) / np.exp(X@beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "igkUvl36XAGV"
   },
   "outputs": [],
   "source": [
    "# IWLS for example 2\n",
    "\n",
    "def IWLS(X,Y,beta_init,maxiter,epsilon):\n",
    "    res = {'FM': None, 'SV': None, 'betas': None}\n",
    "    # Fisher-scoring algorithm\n",
    "    i = 1     # first iteration\n",
    "\n",
    "    beta_i = beta_init\n",
    "    \n",
    "    while i <= maxiter:\n",
    "        W = calc_W_inv(X,beta_i)\n",
    "        Z = calc_Z(X,Y,beta_i)\n",
    "        beta_pred = beta_i\n",
    "        beta_i = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        diff = np.max(np.abs(beta_i - beta_pred))\n",
    "        if diff < epsilon:\n",
    "            break\n",
    "        W = calc_W_inv(X, beta_i)\n",
    "        Z = calc_Z(X, Y, beta_i)\n",
    "\n",
    "        res['SV'] = X.T@W@Z\n",
    "        res['FM'] = X.T@W@X\n",
    "        res['betas'] = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1VDw0-mqZF7x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of parameters: [1.11903977 1.20626365]\n",
      "Estimated Fisher information matrix: [[ 2174.          5581.88169636]\n",
      " [ 5581.88169636 14770.97911355]]\n",
      "Estimated covariance matrix: [[ 0.01547177 -0.00584671]\n",
      " [-0.00584671  0.00227714]]\n"
     ]
    }
   ],
   "source": [
    "# Estimation of betas\n",
    "result1 = IWLS(X,Y,np.ones(2),100,10^(-6))\n",
    "print(f'Estimation of parameters: {result1[\"betas\"]}')      # Estimation of parameters\n",
    "print(f'Estimated Fisher information matrix: {result1[\"FM\"]}')        # Estimated Fisher information matrix\n",
    "print(f'Estimated covariance matrix: {np.linalg.inv(result1[\"FM\"])}')  # Estimated covariance matrix  = Inverse of estimated Fisher information matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEUlAqmFH_mB"
   },
   "source": [
    "Comparison of our custom solution with the built in glm function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6E-UbtQQXALw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -126.23\n",
      "Date:                Thu, 01 Sep 2022   Deviance:                       32.852\n",
      "Time:                        19:43:45   Pearson chi2:                     31.3\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1190      0.124      8.997      0.000       0.875       1.363\n",
      "x1             1.2063      0.048     25.278      0.000       1.113       1.300\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.01547175 -0.0058467 ]\n",
      " [-0.0058467   0.00227714]]\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aic\n",
      "bic\n",
      "bic_deviance\n",
      "bic_llf\n",
      "bse\n",
      "conf_int\n",
      "converged\n",
      "cov_kwds\n",
      "cov_params\n",
      "cov_type\n",
      "deviance\n",
      "df_model\n",
      "df_resid\n",
      "f_test\n",
      "family\n",
      "fit_history\n",
      "fittedvalues\n",
      "get_hat_matrix_diag\n",
      "get_influence\n",
      "get_prediction\n",
      "info_criteria\n",
      "initialize\n",
      "k_constant\n",
      "llf\n",
      "llf_scaled\n",
      "llnull\n",
      "load\n",
      "method\n",
      "mle_settings\n",
      "model\n",
      "mu\n",
      "nobs\n",
      "normalized_cov_params\n",
      "null\n",
      "null_deviance\n",
      "params\n",
      "pearson_chi2\n",
      "plot_added_variable\n",
      "plot_ceres_residuals\n",
      "plot_partial_residuals\n",
      "predict\n",
      "pseudo_rsquared\n",
      "pvalues\n",
      "remove_data\n",
      "resid_anscombe\n",
      "resid_anscombe_scaled\n",
      "resid_anscombe_unscaled\n",
      "resid_deviance\n",
      "resid_pearson\n",
      "resid_response\n",
      "resid_working\n",
      "save\n",
      "scale\n",
      "summary\n",
      "summary2\n",
      "t_test\n",
      "t_test_pairwise\n",
      "tvalues\n",
      "use_t\n",
      "wald_test\n",
      "wald_test_terms\n"
     ]
    }
   ],
   "source": [
    "# to find out what params has `model` object\n",
    "for attr in dir(model):\n",
    "    if not attr.startswith('_'):\n",
    "        print(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7vo_sJaOFiL"
   },
   "source": [
    "Asymptotics:\n",
    "\n",
    "* $ (\\hat{\\beta} - \\beta) \\sim N_{p}(0, I^{-1}(\\beta))$ \n",
    "* Estimated Fisher information matrix  $\\hat{I}(\\hat{\\beta}) = (X^T \\hat{W} X)$  matrix.\n",
    "*  Estimated covariance matrix $\\hat{V} (\\hat{\\beta}) = (X^T \\hat{W} X)^{-1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kB52Ef03Z7uO"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "repet = 50\n",
    "n_observ = np.array([1,2,5,10,100, 500])\n",
    "betas_hat = np.zeros((6, repet, 2))\n",
    "\n",
    "for _, i in enumerate(n_observ):\n",
    "    for j in range(repet):\n",
    "        X1 = np.ones((n*i,))\n",
    "        X2 = np.array([i for i in range(1, n+1)]*i)\n",
    "        X  = np.vstack([X1, np.log(X2)]).T\n",
    "        beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "        lamdas = np.exp(X @ beta) # Means\n",
    "        Y = np.random.poisson(lamdas, n*i)\n",
    "        betas_hat[_, j] = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit().params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nkafuLnXZ7xG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 10\n",
      "[[ 0.08531874 -0.04299982]\n",
      " [-0.04299982  0.02276285]]\n",
      "-0.0015717521114486754\n",
      "Number of observations: 20\n",
      "[[ 0.04120465 -0.02090361]\n",
      " [-0.02090361  0.01113756]]\n",
      "-0.0019093631188979877\n",
      "Number of observations: 50\n",
      "[[ 0.02000824 -0.00974022]\n",
      " [-0.00974022  0.00498364]]\n",
      "-0.003894261248395848\n",
      "Number of observations: 100\n",
      "[[ 0.00763473 -0.0038858 ]\n",
      " [-0.0038858   0.00208036]]\n",
      "0.0012487322512661936\n",
      "Number of observations: 1000\n",
      "[[ 0.00081229 -0.00042735]\n",
      " [-0.00042735  0.00023549]]\n",
      "0.00011000771125407315\n",
      "Number of observations: 5000\n",
      "[[ 1.69735508e-04 -8.09437274e-05]\n",
      " [-8.09437274e-05  4.07133313e-05]]\n",
      "-0.0006636078924959632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(n_observ)):\n",
    "    print(f\"Number of observations: {n_observ[i]*n}\")\n",
    "    print(np.cov((betas_hat[i] - beta).T))\n",
    "    print(np.mean(betas_hat[i] - beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TjcOg79UPRM"
   },
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Use the model from the beginning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8rwWB0Grrmnt"
   },
   "outputs": [],
   "source": [
    "n  = 20\n",
    "m  = 2\n",
    "\n",
    "X1 = np.ones((n*m,))\n",
    "X2 = np.array([i for i in range(1, n+1)]*m)\n",
    "X  = np.vstack([X1, np.log(X2)]).T\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2opFFdr0UfhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -130.61\n",
      "Date:                Thu, 01 Sep 2022   Deviance:                       41.640\n",
      "Time:                        19:43:46   Pearson chi2:                     41.6\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8902      0.128      6.975      0.000       0.640       1.140\n",
      "x1             1.3160      0.049     27.058      0.000       1.221       1.411\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.01628918 -0.00612401]\n",
      " [-0.00612401  0.00236563]]\n"
     ]
    }
   ],
   "source": [
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR3DTTTWV94T"
   },
   "source": [
    "Calculation of Z value\n",
    " $$Z_i = \\frac{\\hat{\\beta_i}}{(I^{-1}(\\hat{\\beta_i}))_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lv8guvybUK-E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -130.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  41.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:43:46</td>     <th>  Pearson chi2:      </th>  <td>  41.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8902</td> <td>    0.128</td> <td>    6.975</td> <td> 0.000</td> <td>    0.640</td> <td>    1.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3160</td> <td>    0.049</td> <td>   27.058</td> <td> 0.000</td> <td>    1.221</td> <td>    1.411</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -130.61\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       41.640\n",
       "Time:                        19:43:46   Pearson chi2:                     41.6\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8902      0.128      6.975      0.000       0.640       1.140\n",
       "x1             1.3160      0.049     27.058      0.000       1.221       1.411\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing statistics from summary table\n",
    "model.summary()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dNjECz1FNw_c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.97468411 27.05792628]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By definition\n",
    "\n",
    "z_stat = model.params / np.sqrt(np.diag(model.cov_params()))\n",
    "print(z_stat)\n",
    "z_stat == model.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9mHfejdWULDh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval: [3.06558834e-012 3.08138804e-161]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-values of the test\n",
    "p_val = 2*scipy.stats.norm.sf(z_stat, loc=0, scale=1)\n",
    "print(f'pval: {p_val}')\n",
    "p_val == model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7GdfbeqdYOIv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5% CI = 1.2207091370738408,ESTIM = 1.31603743170923, 97.5% CI = 1.4113657263446193\n",
      "[[0.64002414 1.14032095]\n",
      " [1.22070914 1.41136573]]\n"
     ]
    }
   ],
   "source": [
    "### 100(1-alpha) confidence interval\n",
    "alpha = 0.05\n",
    "u = scipy.stats.norm.ppf(1-alpha/2,0,1)\n",
    "CI_LB = model.params[1] - u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "CI_UB = model.params[1] + u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "\n",
    "print(f\"2.5% CI = {CI_LB},ESTIM = {model.params[1]}, 97.5% CI = {CI_UB}\")\n",
    "\n",
    "\n",
    "# built in function\n",
    "print(model.conf_int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkhFJFXceHjn"
   },
   "source": [
    "Question:\n",
    "\n",
    "* Compare hypothesis testing in LM vs. GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwXaIg0peQee"
   },
   "source": [
    "# Deviance\n",
    "\n",
    "Deviance is a measure of goodness of fit of a GLM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjNUyZoZeStY"
   },
   "source": [
    "Log-likelihood of the saturated model is the highest possible one with given data, $\\tilde{\\mu}_i = y_i$ and $\\tilde{\\theta_i} = \\theta(y) = (b')^{-1}(y_i)$.\n",
    "$$l(\\tilde{\\mu},\\phi;y)=\\sum_{i=1}^{n}\\frac{y_{i}\\tilde{\\theta}_{i}-b(\\tilde{\\theta}_{i})}{a_{i}(\\phi)}+\\sum_{i=1}^{n}c(y_i,\\phi)$$\n",
    "\n",
    "Scale deviance statistics:\n",
    "$${S(y,\\hat{\\mu},\\phi)}=2\\left[l(\\tilde{\\mu},\\phi;y)-l(\\hat{\\mu},\\phi;y)\\right]\n",
    "=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}(\\phi)}.\n",
    "$$\n",
    "\n",
    "Deviance:\n",
    "Let $a_{i}(\\phi)=a_{i}\\phi$, then\n",
    "$$S(y,\\hat{\\mu},\\phi)=\\frac{D(y,\\hat{\\mu})}{\\phi},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "D(y,\\hat{\\mu})=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}}\n",
    "$$\n",
    "\n",
    "### Comparison of two models\n",
    "\n",
    "Assume model $D_0$ with $p_0$ paramters and its sub-model $D_1$ with $p_1$ parameters, then\n",
    "$$ \\frac{1}{\\phi} (D_0 - D_1) \\sim \\chi(p_0 - p_1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLxMlbIKeTe5"
   },
   "source": [
    "Question:\n",
    "* Can we take deviance as a measure of the model quality?\n",
    "* Can we use deviance as a measure of the saturated model quality?\n",
    "* Complete the sentence: Compare two GLMs with deviance is like compare two LMs with ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5PVvXp_SpDUx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -129.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  40.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:43:46</td>     <th>  Pearson chi2:      </th>  <td>  40.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8358</td> <td>    0.136</td> <td>    6.150</td> <td> 0.000</td> <td>    0.569</td> <td>    1.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3215</td> <td>    0.049</td> <td>   27.014</td> <td> 0.000</td> <td>    1.226</td> <td>    1.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0852</td> <td>    0.072</td> <td>    1.180</td> <td> 0.238</td> <td>   -0.056</td> <td>    0.227</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       37\n",
       "Model Family:                 Poisson   Df Model:                            2\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -129.92\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       40.252\n",
       "Time:                        19:43:46   Pearson chi2:                     40.1\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8358      0.136      6.150      0.000       0.569       1.102\n",
       "x1             1.3215      0.049     27.014      0.000       1.226       1.417\n",
       "x2             0.0852      0.072      1.180      0.238      -0.056       0.227\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add random variable to the previous model \n",
    "Z = scipy.stats.uniform.rvs(loc=0, scale=1, size=n*m)\n",
    "model_0 = sm.GLM(endog=Y, exog=np.hstack([X, Z[:, None]]), family=sm.families.Poisson()).fit()\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_O24NMRTPjoA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -130.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  41.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:43:46</td>     <th>  Pearson chi2:      </th>  <td>  41.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8902</td> <td>    0.128</td> <td>    6.975</td> <td> 0.000</td> <td>    0.640</td> <td>    1.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3160</td> <td>    0.049</td> <td>   27.058</td> <td> 0.000</td> <td>    1.221</td> <td>    1.411</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -130.61\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       41.640\n",
       "Time:                        19:43:46   Pearson chi2:                     41.6\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8902      0.128      6.975      0.000       0.640       1.140\n",
       "x1             1.3160      0.049     27.058      0.000       1.221       1.411\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proposed model\n",
    "\n",
    "model_1 = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WbtdZzD6Pjx6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    39</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -698.49</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  1177.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:43:46</td>     <th>  Pearson chi2:      </th> <td>1.04e+03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th> <td>2.842e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.0496</td> <td>    0.021</td> <td>  194.001</td> <td> 0.000</td> <td>    4.009</td> <td>    4.091</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       39\n",
       "Model Family:                 Poisson   Df Model:                            0\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -698.49\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       1177.4\n",
       "Time:                        19:43:46   Pearson chi2:                 1.04e+03\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):          2.842e-14\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.0496      0.021    194.001      0.000       4.009       4.091\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null model\n",
    "\n",
    "model_n = sm.GLM(endog=Y, exog=X[:, 0], family=sm.families.Poisson()).fit()\n",
    "model_n.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "508GBQM_Pj5L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                        0\n",
      "Model Family:                 Poisson   Df Model:                           39\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -109.79\n",
      "Date:                Thu, 01 Sep 2022   Deviance:                   7.2831e-14\n",
      "Time:                        19:52:19   Pearson chi2:                 1.99e-25\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.6931      0.707      0.980      0.327      -0.693       2.079\n",
      "x2             0.6931      0.707      0.980      0.327      -0.693       2.079\n",
      "x3             2.5649      0.277      9.248      0.000       2.021       3.109\n",
      "x4             2.5649      0.277      9.248      0.000       2.021       3.109\n",
      "x5             2.7081      0.258     10.488      0.000       2.202       3.214\n",
      "x6             2.9957      0.224     13.397      0.000       2.557       3.434\n",
      "x7             3.2189      0.200     16.094      0.000       2.827       3.611\n",
      "x8             3.9318      0.140     28.079      0.000       3.657       4.206\n",
      "x9             3.6889      0.158     23.331      0.000       3.379       3.999\n",
      "x10            3.8712      0.144     26.820      0.000       3.588       4.154\n",
      "x11            4.3041      0.116     37.025      0.000       4.076       4.532\n",
      "x12            4.0943      0.129     31.715      0.000       3.841       4.347\n",
      "x13            4.2047      0.122     34.417      0.000       3.965       4.444\n",
      "x14            4.2047      0.122     34.417      0.000       3.965       4.444\n",
      "x15            4.5218      0.104     43.371      0.000       4.317       4.726\n",
      "x16            4.4427      0.108     40.959      0.000       4.230       4.655\n",
      "x17            4.4998      0.105     42.689      0.000       4.293       4.706\n",
      "x18            4.5218      0.104     43.371      0.000       4.317       4.726\n",
      "x19            4.8122      0.090     53.370      0.000       4.635       4.989\n",
      "x20            4.8675      0.088     55.498      0.000       4.696       5.039\n",
      "x21            1.0986      0.577      1.903      0.057      -0.033       2.230\n",
      "x22            1.6094      0.447      3.599      0.000       0.733       2.486\n",
      "x23            2.3026      0.316      7.281      0.000       1.683       2.922\n",
      "x24            2.8904      0.236     12.263      0.000       2.428       3.352\n",
      "x25            3.4012      0.183     18.629      0.000       3.043       3.759\n",
      "x26            3.0445      0.218     13.952      0.000       2.617       3.472\n",
      "x27            3.5264      0.171     20.562      0.000       3.190       3.862\n",
      "x28            3.8501      0.146     26.395      0.000       3.564       4.136\n",
      "x29            3.5553      0.169     21.034      0.000       3.224       3.887\n",
      "x30            3.7842      0.151     25.101      0.000       3.489       4.080\n",
      "x31            4.1589      0.125     33.271      0.000       3.914       4.404\n",
      "x32            4.2195      0.121     34.795      0.000       3.982       4.457\n",
      "x33            4.4067      0.110     39.905      0.000       4.190       4.623\n",
      "x34            4.3944      0.111     39.550      0.000       4.177       4.612\n",
      "x35            4.4773      0.107     42.001      0.000       4.268       4.686\n",
      "x36            4.5850      0.101     45.389      0.000       4.387       4.783\n",
      "x37            4.6634      0.097     48.013      0.000       4.473       4.854\n",
      "x38            4.6151      0.100     46.381      0.000       4.420       4.810\n",
      "x39            4.8122      0.090     53.370      0.000       4.635       4.989\n",
      "x40            4.8520      0.088     54.894      0.000       4.679       5.025\n",
      "==============================================================================\n",
      "Residual deviance is: 7.283063041521163e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/data/miniconda3/lib/python3.9/site-packages/statsmodels/regression/_tools.py:121: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  scale = np.dot(wresid, wresid) / df_resid\n"
     ]
    }
   ],
   "source": [
    "# Saturated model CANNOT BY OBTAINED BY STATSMODELS BY DEFAULT 'CAUSE THEY PREVENT ZERO DIVISION\n",
    "\n",
    "# BUT MY WORKAROUND WHICH PROBABLY WILL NOT WORK IN COLAB AS WE DO NOT HAVE ACCESS TO MODULES IS\n",
    "# TO COMMENT OUT ROWS 1227-1229 IN MOST RECENT VERSION \n",
    "# (SEE https://github.com/statsmodels/statsmodels/blob/main/statsmodels/genmod/generalized_linear_model.py)\n",
    "\n",
    "I = np.diag(np.ones((m*n,)))\n",
    "\n",
    "\n",
    "model_s = sm.GLM(endog=Y, exog=I, family=sm.families.Poisson()).fit()\n",
    "print(model_s.summary())\n",
    "print(f'Residual deviance is: {model_s.deviance}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWfxVEHguydO"
   },
   "source": [
    "For Poisson model:\n",
    "$$D = 2 \\sum_{i=1}^n y_i log( \\frac{y_i}{\\hat{\\mu_i}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Dm5NQ5Jr509"
   },
   "outputs": [],
   "source": [
    "mu_est_0 = model_0.predict()\n",
    "mu_est_1 = model_1.predict()\n",
    "\n",
    "Dev_0 = 2*np.sum(Y*np.log(Y/mu_est_0))\n",
    "print(Dev_0)\n",
    "Dev_1 = 2*np.sum(Y*np.log(Y/mu_est_1))\n",
    "print(Dev_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9SuGMWFwhDM"
   },
   "source": [
    "## Anova testing \n",
    "from anova.glm?\n",
    "\n",
    "The table will optionally contain test statistics (and P values) comparing the reduction in deviance for the row to the residuals. For models with known dispersion (e.g., binomial and Poisson fits) the chi-squared test is most appropriate, and for those with dispersion estimated by moments (e.g., gaussian, quasibinomial and quasipoisson fits) the F test is most appropriate. \n",
    "\n",
    "Mallows' Cp statistic is the residual deviance plus twice the estimate of $sigma^2$ times the residual degrees of freedom, which is closely related to AIC (and a multiple of it if the dispersion is known). You can also choose \"LRT\" and \"Rao\" for likelihood ratio tests and Rao's efficient score test. The former is synonymous with \"Chisq\" (although both have an asymptotic chi-square distribution). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8MegJJTsqvK"
   },
   "outputs": [],
   "source": [
    "anova(model_1)\n",
    "anova(model_1, test = \"Cp\")\n",
    "anova(model_1, test = \"Chisq\")\n",
    "\n",
    "anova(model_1, model_0, test = \"Rao\")\n",
    "anova(model_1, model_0, test = \"LRT\")   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UchWeYjOxI7X"
   },
   "outputs": [],
   "source": [
    "# p-value of deviance tst\n",
    "# H0: model fit data\n",
    "p_dev <- pchisq(model_1$deviance, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "p_dev\n",
    "\n",
    "# critical value\n",
    "C_val <- qchisq(0.05, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "C_val\n",
    "\n",
    "#summary(model_1)\n",
    "#pchisq(1168 - 44, df=(39-38))\n",
    "\n",
    "anova(model_1,model_s, test = \"LRT\")   # saturated vs. final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7uXyJRAUKAd"
   },
   "outputs": [],
   "source": [
    "class anova():\n",
    "    def _call_(*models, test='F'):\n",
    "        if len(models) == 1:\n",
    "            \n",
    "    def _F_():\n",
    "        pass\n",
    "    def _chisq_():\n",
    "        pass\n",
    "    def _rao_():\n",
    "        pass\n",
    "    def _lrt_():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz4Ek6Y464bE"
   },
   "source": [
    "## Rao statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrTIUoUKUKDg"
   },
   "outputs": [],
   "source": [
    "######## Rao score statistics\n",
    "\n",
    "Rao <- sum((Y-mu_est_1)^2/mu_est_1)\n",
    "Rao\n",
    "# p-hodnota testu adekvatnosti modelu (pomoci Raovy statistiky)\n",
    "# H0: model dobre popisuje data\n",
    "prao <- pchisq(Rao, model$df.residual, ncp=0, lower.tail = FALSE); \n",
    "prao\n",
    "\n",
    "######  pomoci saturovaneho modelu\n",
    "anova(model_1,model_s, test = \"Rao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H73SzqdlUKIT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAmB4PDZJKEl"
   },
   "source": [
    "# Your turn:\n",
    "1. Generate data with followings parameters\n",
    " * $Y \\sim Poi(\\mu_i)$, where $E[Y_i] = \\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} = x_i^T \\beta \\  \\Rightarrow \\ q(\\mu_i) = \\mu_i =  x_i^T \\beta  = \\eta_i$\n",
    "* $X_{i1} \\sim N(50,10)$\n",
    "* $X_{i2} \\sim U(10,60)$\n",
    "* $X_{i3} \\sim Ber(0.45)$\n",
    "* $n = 40$\n",
    "2. Compute $\\hat{\\mu_i}$  for saturated, null,\"full\",\"best\" models.\n",
    "3. Compute Deviance, Rao, Wald statistics for your model and compare final model with the saturated and \"full\" ones.\n",
    "4. Generate 100x data for  $n \\in \\{20,40,60,80,100 \\}$ and plot $(\\hat{\\beta_i} -\\beta_i)$ vs. $(n)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O60Qhn1rV7Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3+qISYKNbOXYZbGEQmi1a",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01ZLMA_ex03.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
