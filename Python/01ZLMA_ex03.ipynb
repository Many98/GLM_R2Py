{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Many98/GLM_R2Py/blob/main/Python/01ZLMA_ex03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-i6MbNFm4Zt"
   },
   "source": [
    "# 01ZLMA - Exercise 03\n",
    "Exercise 03 of the course 01ZLMA. \n",
    "\n",
    "## Contents\n",
    "\n",
    "* Statistical Inference\n",
    " ---\n",
    "* Testing\n",
    " ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "593Mg4ZbbeEE"
   },
   "source": [
    "#  Necessary theory recap from Lecture 04\n",
    "\n",
    "Under the conditions of regularity holds\n",
    "\n",
    "1.  $ \\ U(\\beta) \\sim N_{p}(0,I(\\beta)) \\Rightarrow  I^{-\\frac{1}{2}}(\\beta)\\, U(\\beta) {\\stackrel{D}{\\longrightarrow}} N_{p}(0, 1)$\n",
    "2. $ U(\\beta)I^{-1}(\\beta)U(\\beta)\\sim \\chi^{2}(p) \\Rightarrow U(\\beta)^T I^{-1}(\\beta)U(\\beta)  {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "3. Consistency of $\\hat{\\beta}$ and Wald statistics: \\\\\n",
    " $\\hat{\\beta}\\sim N_{p}(\\beta,I^{-1}(\\beta)) \\Rightarrow\n",
    "(\\hat{\\beta}-\\beta)^T I(\\beta)(\\hat{\\beta}-\\beta) {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2c7jDIXSGGL"
   },
   "source": [
    "Saturated and null model\n",
    "\n",
    "* Null model: $\\mu_i = \\mu, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Null Model assumes one parameter for all of the data points, which means you only estimate 1 parameter. \n",
    "* Saturated model: $Y_i = \\hat{\\mu_i}, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Saturated Model is a model that assumes each data point has its own parameters, which means you have n parameters to estimate.\n",
    "* Proposed Model:  model, where you try to explain your data points with $p$ parameters + an intercept term, so you have p+1 parameters, where $1 \\leq p \\leq n$.\n",
    "\n",
    "Questions:\n",
    "* What is the difference between null and saturated model?\n",
    "* Which model has greater log-likelihoood value?\n",
    "* Which model has the highest log-likelihood value?\n",
    "* What can you say about asymptotic distributions of $\\hat{\\beta}$ and $U(\\hat{\\beta})$ for saturated model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um9ho8cQHobx"
   },
   "source": [
    "## Let's code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wV3e4NaLbVZg"
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "library(MASS)\n",
    "\n",
    "#For sure: set dplyr functions\n",
    "select    <- dplyr::select;\n",
    "rename    <- dplyr::rename;\n",
    "mutate    <- dplyr::mutate; \n",
    "summarize <- dplyr::summarize;\n",
    "arrange   <- dplyr::arrange;\n",
    "slice     <- dplyr::slice;\n",
    "filter    <- dplyr::filter;\n",
    "recode    <- dplyr::recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-kZTsg7FZoM"
   },
   "source": [
    "Use Example 2 from the last Exercise 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n  = 20 # n observations\n",
    "m  = 2 # m parameters to estimate\n",
    "X1 = np.ones((n*m,))  # Intercept\n",
    "X2 = np.array([i for i in range(1, n+1)] * m) # Regressors\n",
    "X = np.vstack([X1, np.log(X2)]).T # design matrix\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m) # Response variable with Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "jU_eFKcbWMUy"
   },
   "outputs": [
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Many98/GLM_R2Py/blob/main/Python/01ZLMA_ex02_solution.ipynb" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-i6MbNFm4Zt"
      },
      "source": [
        "# 01ZLMA - Exercise 03\n",
        "Exercise 03 of the course 01ZLMA. \n",
        "\n",
        "## Contents\n",
        "\n",
        "* Statistical Inference\n",
        " ---\n",
        "* Testing\n",
        " ---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "593Mg4ZbbeEE"
      },
      "source": [
        "#  Necessary theory recap from Lecture 04\n",
        "\n",
        "Under the conditions of regularity holds\n",
        "\n",
        "1.  $ \\ U(\\beta) \\sim N_{p}(0,I(\\beta)) \\Rightarrow  I^{-\\frac{1}{2}}(\\beta)\\, U(\\beta) {\\stackrel{D}{\\longrightarrow}} N_{p}(0, 1)$\n",
        "2. $ U(\\beta)I^{-1}(\\beta)U(\\beta)\\sim \\chi^{2}(p) \\Rightarrow U(\\beta)^T I^{-1}(\\beta)U(\\beta)  {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
        "3. Consistency of $\\hat{\\beta}$ and Wald statistics: \\\\\n",
        " $\\hat{\\beta}\\sim N_{p}(\\beta,I^{-1}(\\beta)) \\Rightarrow\n",
        "(\\hat{\\beta}-\\beta)^T I(\\beta)(\\hat{\\beta}-\\beta) {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2c7jDIXSGGL"
      },
      "source": [
        "Saturated and null model\n",
        "\n",
        "* Null model: $\\mu_i = \\mu, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
        "The Null Model assumes one parameter for all of the data points, which means you only estimate 1 parameter. \n",
        "* Saturated model: $Y_i = \\hat{\\mu_i}, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
        "The Saturated Model is a model that assumes each data point has its own parameters, which means you have n parameters to estimate.\n",
        "* Proposed Model:  model, where you try to explain your data points with $p$ parameters + an intercept term, so you have p+1 parameters, where $1 \\leq p \\leq n$.\n",
        "\n",
        "Questions:\n",
        "* What is the difference between null and saturated model?\n",
        "* Which model has greater log-likelihoood value?\n",
        "* Which model has the highest log-likelihood value?\n",
        "* What can you say about asymptotic distributions of $\\hat{\\beta}$ and $U(\\hat{\\beta})$ for saturated model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um9ho8cQHobx"
      },
      "source": [
        "## Let's code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV3e4NaLbVZg"
      },
      "source": [
        "library(tidyverse)\n",
        "library(lubridate)\n",
        "library(MASS)\n",
        "\n",
        "#For sure: set dplyr functions\n",
        "select    <- dplyr::select;\n",
        "rename    <- dplyr::rename;\n",
        "mutate    <- dplyr::mutate; \n",
        "summarize <- dplyr::summarize;\n",
        "arrange   <- dplyr::arrange;\n",
        "slice     <- dplyr::slice;\n",
        "filter    <- dplyr::filter;\n",
        "recode    <- dplyr::recode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-kZTsg7FZoM"
      },
      "source": [
        "Use Example 2 from the last Exercise 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZlx_DRmNlls"
      },
      "source": [
        "n  = 20 # n observations\n",
        "m  = 2 # m parameters to estimate\n",
        "X1 = rep(rep(1,n),m)  # Intercept\n",
        "X2 = rep(seq(1,n,1),m) # Regressors\n",
        "X  = cbind(X1,log(X2)) # \n",
        "beta = c(0.9, 1.3) # Regression coefficients\n",
        "lamdas = exp(X%*%beta) # Means\n",
        "Y  = rpois(n*m,lamdas) # Response variable with Poisson distribution\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDEl06ReNltJ"
      },
      "source": [
        "model <- glm(formula=Y~log(X2),family=poisson(link = \"log\"))\n",
        "summary(model) \n",
        "\n",
        "beta.e <- coefficients(model); beta.e  # Estimated parameters\n",
        "y.hat  <- model$fitted.values # Fitted values (Estimation of response)\n",
        "\n",
        "\n",
        "## Plot original data points and estimation values\n",
        "plot(X2,Y, col=\"red\", cex=1.5, lwd=2, \n",
        "      main=\"Poisson model\",\n",
        "      xlab=\"Year Quoter\",\n",
        "      ylab=\"Number of cases\",\n",
        "      cex.lab=1.2)\n",
        "lines(unique(y.hat), col=\"blue\", type = \"l\", lwd=3)\n",
        "text <- c(\"model\", \"data\")\n",
        "legend(x=1, y=160, text, col = c(4,2), bty=\"n\", lwd = 2,  cex=1.3, lty=c(1,0))\n",
        "dev.off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU_eFKcbWMUy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repetition using custom function:"
      ],
      "metadata": {
        "id": "3N8x-oi3HAKK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T477n--PWMXz"
      },
      "source": [
        "# function to calcualate weights W\n",
        "calc_W_inv <- function(X,beta){\n",
        "  n = length(X[,1])\n",
        "  W = diag(c(exp(X%*%beta)),n,n)\n",
        "  return(W)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcA9wuh1WMtL"
      },
      "source": [
        "# function to calcualate weights Z\n",
        "calc_Z <- function(X,Y,beta){\n",
        "  Z = X%*%(beta) + (Y-exp(X%*%beta))/exp(X%*%beta)\n",
        "  return(Z)\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igkUvl36XAGV"
      },
      "source": [
        "# IWLS for example 2\n",
        "IWLS <- function(X,Y,beta_init,maxiter,epsilon){\n",
        "  result <- list(FM=NA, SV=NA, betas=NA)\n",
        "  # Fisher-scoring algorithm\n",
        "  i <- 1     # first iteration\n",
        "  convergence <- F\n",
        "  beta_i <- beta_init\n",
        "\n",
        "\n",
        "  while (convergence == F & i <= maxiter){\n",
        "    W = calc_W_inv(X,beta_i)\n",
        "    Z = calc_Z(X,Y,beta_i)\n",
        "    beta_pred = beta_i\n",
        "    beta_i = solve(t(X)%*%W%*%X, t(X)%*%W%*%Z)\n",
        "    diff   = max(abs(beta_i - beta_pred))\n",
        "    if (diff>=epsilon){\n",
        "      i <- i+1\n",
        "    }\n",
        "    else\n",
        "      convergence <- T\n",
        "    }\n",
        "    W    <- calc_W_inv(X,beta_i)\n",
        "    Z = calc_Z(X,Y,beta_i)\n",
        "    result$SV <- t(X)%*%W%*%Z\n",
        "    result$FM <- t(X)%*%W%*%X\n",
        "    result$betas <- solve(t(X)%*%W%*%X, t(X)%*%W%*%Z)\n",
        "\n",
        "  return(result)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VDw0-mqZF7x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS1s7akiXAJJ"
      },
      "source": [
        "# Estimation of betas\n",
        "result1 <- IWLS(X,Y,c(1,1),100,10^(-6))\n",
        "result1$betas      # Estimation of parameters\n",
        "#result1$FM         # Estimated Fisher information matrix\n",
        "solve(result1$FM)  # Estimated covariance matrix  = Inverse of estimated Fisher information matrix\n",
        "result1$SV         # Score Vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison of our custom solution with the built in glm function:"
      ],
      "metadata": {
        "id": "PEUlAqmFH_mB"
      }
    },
>>>>>>> b8ac98bcd742d9d06ee2ed2e409465406c13e4fd
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -129.90\n",
      "Date:                Thu, 01 Sep 2022   Deviance:                       40.438\n",
      "Time:                        13:20:19   Pearson chi2:                     40.1\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9986      0.128      7.823      0.000       0.748       1.249\n",
      "x1             1.2493      0.049     25.582      0.000       1.154       1.345\n",
      "==============================================================================\n",
      "estimated params are:[0.99858765 1.24932415]\n",
      "fitted values are:[  2.71444538   6.45305176  10.70927845  15.3408418   20.27314892\n",
      "  25.45917071  30.86615224  36.46978757  42.25122597  48.19536269\n",
      "  54.28978652  60.52409378  66.88942062  73.37811251  79.98348347\n",
      "  86.69963636  93.52132578 100.44385152 107.46297451 114.57484944\n",
      "   2.71444538   6.45305176  10.70927845  15.3408418   20.27314892\n",
      "  25.45917071  30.86615224  36.46978757  42.25122597  48.19536269\n",
      "  54.28978652  60.52409378  66.88942062  73.37811251  79.98348347\n",
      "  86.69963636  93.52132578 100.44385152 107.46297451 114.57484944]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to create models we can use standard api or formula (r-like) api in statsmodels\n",
    "# formula api requires dataset (pandas) and formula\n",
    "d = pd.DataFrame(data={'Y': Y, 'X1': X1, 'X2':X2})\n",
    "#model = smf.glm(formula='Y~np.log(X2)', data=d, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# standard api requires specifying endog (response) and exog (explanatory) design matrices\n",
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "beta_e = model.params; print(f'estimated params are:{beta_e}')\n",
    "y_hat = model.predict(); print(f'fitted values are:{y_hat}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2, Y, color='red', marker='o')\n",
    "ax.plot(np.unique(y_hat), color='blue')\n",
    "ax.set_title('Poisson model')\n",
    "ax.set_xlabel('Year Quoter')\n",
    "ax.set_ylabel('Number of cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N8x-oi3HAKK"
   },
   "source": [
    "Repetition using custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calcualate weights W\n",
    "def calc_W_inv(X, beta):\n",
    "    return np.diag(np.exp(X @ beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "xcA9wuh1WMtL"
   },
   "outputs": [],
   "source": [
    "# function to calcualate weights Z\n",
    "def calc_Z(X,Y,beta):\n",
    "    return X@beta + (Y - np.exp(X@beta)) / np.exp(X@beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "igkUvl36XAGV"
   },
   "outputs": [],
   "source": [
    "# IWLS for example 2\n",
    "\n",
    "def IWLS(X,Y,beta_init,maxiter,epsilon):\n",
    "    res = {'FM': None, 'SV': None, 'betas': None}\n",
    "    # Fisher-scoring algorithm\n",
    "    i = 1     # first iteration\n",
    "\n",
    "    beta_i = beta_init\n",
    "    \n",
    "    while i <= maxiter:\n",
    "        W = calc_W_inv(X,beta_i)\n",
    "        Z = calc_Z(X,Y,beta_i)\n",
    "        beta_pred = beta_i\n",
    "        beta_i = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        diff = np.max(np.abs(beta_i - beta_pred))\n",
    "        if diff < epsilon:\n",
    "            break\n",
    "        W = calc_W_inv(X, beta_i)\n",
    "        Z = calc_Z(X, Y, beta_i)\n",
    "\n",
    "        res['SV'] = X.T@W@Z\n",
    "        res['FM'] = X.T@W@X\n",
    "        res['betas'] = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "1VDw0-mqZF7x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of parameters: [0.99858765 1.24932415]\n",
      "Estimated Fisher information matrix: [[ 2153.          5546.35109572]\n",
      " [ 5546.35109572 14707.26331416]]\n",
      "Estimated covariance matrix: [[ 0.01629203 -0.00614399]\n",
      " [-0.00614399  0.00238499]]\n"
     ]
    }
   ],
   "source": [
    "# Estimation of betas\n",
    "result1 = IWLS(X,Y,np.ones(2),100,10^(-6))\n",
    "print(f'Estimation of parameters: {result1[\"betas\"]}')      # Estimation of parameters\n",
    "print(f'Estimated Fisher information matrix: {result1[\"FM\"]}')        # Estimated Fisher information matrix\n",
    "print(f'Estimated covariance matrix: {np.linalg.inv(result1[\"FM\"])}')  # Estimated covariance matrix  = Inverse of estimated Fisher information matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEUlAqmFH_mB"
   },
   "source": [
    "Comparison of our custom solution with the built in glm function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "6E-UbtQQXALw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -129.90\n",
      "Date:                Thu, 01 Sep 2022   Deviance:                       40.438\n",
      "Time:                        14:01:03   Pearson chi2:                     40.1\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9986      0.128      7.823      0.000       0.748       1.249\n",
      "x1             1.2493      0.049     25.582      0.000       1.154       1.345\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.016292   -0.00614398]\n",
      " [-0.00614398  0.00238499]]\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aic\n",
      "bic\n",
      "bic_deviance\n",
      "bic_llf\n",
      "bse\n",
      "conf_int\n",
      "converged\n",
      "cov_kwds\n",
      "cov_params\n",
      "cov_type\n",
      "deviance\n",
      "df_model\n",
      "df_resid\n",
      "f_test\n",
      "family\n",
      "fit_history\n",
      "fittedvalues\n",
      "get_hat_matrix_diag\n",
      "get_influence\n",
      "get_prediction\n",
      "info_criteria\n",
      "initialize\n",
      "k_constant\n",
      "llf\n",
      "llf_scaled\n",
      "llnull\n",
      "load\n",
      "method\n",
      "mle_settings\n",
      "model\n",
      "mu\n",
      "nobs\n",
      "normalized_cov_params\n",
      "null\n",
      "null_deviance\n",
      "params\n",
      "pearson_chi2\n",
      "plot_added_variable\n",
      "plot_ceres_residuals\n",
      "plot_partial_residuals\n",
      "predict\n",
      "pseudo_rsquared\n",
      "pvalues\n",
      "remove_data\n",
      "resid_anscombe\n",
      "resid_anscombe_scaled\n",
      "resid_anscombe_unscaled\n",
      "resid_deviance\n",
      "resid_pearson\n",
      "resid_response\n",
      "resid_working\n",
      "save\n",
      "scale\n",
      "summary\n",
      "summary2\n",
      "t_test\n",
      "t_test_pairwise\n",
      "tvalues\n",
      "use_t\n",
      "wald_test\n",
      "wald_test_terms\n"
     ]
    }
   ],
   "source": [
    "# to find out what params has `model` object\n",
    "for attr in dir(model):\n",
    "    if not attr.startswith('_'):\n",
    "        print(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7vo_sJaOFiL"
   },
   "source": [
    "Asymptotics:\n",
    "\n",
    "* $ (\\hat{\\beta} - \\beta) \\sim N_{p}(0, I^{-1}(\\beta))$ \n",
    "* Estimated Fisher information matrix  $\\hat{I}(\\hat{\\beta}) = (X^T \\hat{W} X)$  matrix.\n",
    "*  Estimated covariance matrix $\\hat{V} (\\hat{\\beta}) = (X^T \\hat{W} X)^{-1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "kB52Ef03Z7uO"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "repet = 50\n",
    "n_observ = np.array([1,2,5,10,100, 500])\n",
    "betas_hat = np.zeros((6, repet, 2))\n",
    "\n",
    "for _, i in enumerate(n_observ):\n",
    "    for j in range(repet):\n",
    "        X1 = np.ones((n*i,))\n",
    "        X2 = np.array([i for i in range(1, n+1)]*i)\n",
    "        X  = np.vstack([X1, np.log(X2)]).T\n",
    "        beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "        lamdas = np.exp(X @ beta) # Means\n",
    "        Y = np.random.poisson(lamdas, n*i)\n",
    "        betas_hat[_, j] = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit().params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "nkafuLnXZ7xG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 10\n",
      "[[ 0.08437699 -0.04172813]\n",
      " [-0.04172813  0.02199841]]\n",
      "-0.030001563817229435\n",
      "Number of observations: 20\n",
      "[[ 0.04244661 -0.02085902]\n",
      " [-0.02085902  0.01071131]]\n",
      "-0.008175956892908662\n",
      "Number of observations: 50\n",
      "[[ 0.02132238 -0.01038939]\n",
      " [-0.01038939  0.00524236]]\n",
      "-0.00646356533438539\n",
      "Number of observations: 100\n",
      "[[ 0.01142505 -0.00558841]\n",
      " [-0.00558841  0.00284806]]\n",
      "0.0038190360302381887\n",
      "Number of observations: 1000\n",
      "[[ 0.00103768 -0.00048745]\n",
      " [-0.00048745  0.00024265]]\n",
      "0.0009550607298383252\n",
      "Number of observations: 5000\n",
      "[[ 1.49200565e-04 -7.05136806e-05]\n",
      " [-7.05136806e-05  3.49465624e-05]]\n",
      "-0.0005336414306926718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(n_observ)):\n",
    "    print(f\"Number of observations: {n_observ[i]*n}\")\n",
    "    print(np.cov((betas_hat[i] - beta).T))\n",
    "    print(np.mean(betas_hat[i] - beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TjcOg79UPRM"
   },
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Use the model from the beginning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "8rwWB0Grrmnt"
   },
   "outputs": [],
   "source": [
    "n  = 20\n",
    "m  = 2\n",
    "\n",
    "X1 = np.ones((n*m,))\n",
    "X2 = np.array([i for i in range(1, n+1)]*m)\n",
    "X  = np.vstack([X1, np.log(X2)]).T\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "2opFFdr0UfhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -128.15\n",
      "Date:                Thu, 01 Sep 2022   Deviance:                       36.747\n",
      "Time:                        14:42:59   Pearson chi2:                     36.3\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8953      0.129      6.951      0.000       0.643       1.148\n",
      "x1             1.3017      0.049     26.497      0.000       1.205       1.398\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.01659083 -0.00624147]\n",
      " [-0.00624147  0.00241348]]\n"
     ]
    }
   ],
   "source": [
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR3DTTTWV94T"
   },
   "source": [
    "Calculation of Z value\n",
    " $$Z_i = \\frac{\\hat{\\beta_i}}{(I^{-1}(\\hat{\\beta_i}))_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "lv8guvybUK-E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -128.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  36.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:54:11</td>     <th>  Pearson chi2:      </th>  <td>  36.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8953</td> <td>    0.129</td> <td>    6.951</td> <td> 0.000</td> <td>    0.643</td> <td>    1.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3017</td> <td>    0.049</td> <td>   26.497</td> <td> 0.000</td> <td>    1.205</td> <td>    1.398</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -128.15\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       36.747\n",
       "Time:                        14:54:11   Pearson chi2:                     36.3\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.8953      0.129      6.951      0.000       0.643       1.148\n",
       "x1             1.3017      0.049     26.497      0.000       1.205       1.398\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing statistics from summary table\n",
    "model.summary()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "dNjECz1FNw_c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.95086526 26.49721093]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By definition\n",
    "\n",
    "z_stat = model.params / np.sqrt(np.diag(model.cov_params()))\n",
    "print(z_stat)\n",
    "z_stat == model.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "9mHfejdWULDh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval: [3.63052500e-012 1.04368804e-154]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-values of the test\n",
    "p_val = 2*scipy.stats.norm.sf(z_stat, loc=0, scale=1)\n",
    "print(f'pval: {p_val}')\n",
    "p_val == model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "7GdfbeqdYOIv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5% CI = 1.2054454649443955,ESTIM = 1.3017329458358302, 97.5% CI = 1.398020426727265\n",
      "[[0.64285505 1.14776295]\n",
      " [1.20544546 1.39802043]]\n"
     ]
    }
   ],
   "source": [
    "### 100(1-alpha) confidence interval\n",
    "alpha = 0.05\n",
    "u = scipy.stats.norm.ppf(1-alpha/2,0,1)\n",
    "CI_LB = model.params[1] - u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "CI_UB = model.params[1] + u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "\n",
    "print(f\"2.5% CI = {CI_LB},ESTIM = {model.params[1]}, 97.5% CI = {CI_UB}\")\n",
    "\n",
    "\n",
    "# built in function\n",
    "print(model.conf_int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkhFJFXceHjn"
   },
   "source": [
    "Question:\n",
    "\n",
    "* Compare hypothesis testing in LM vs. GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwXaIg0peQee"
   },
   "source": [
    "# Deviance\n",
    "\n",
    "Deviance is a measure of goodness of fit of a GLM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjNUyZoZeStY"
   },
   "source": [
    "Log-likelihood of the saturated model is the highest possible one with given data, $\\tilde{\\mu}_i = y_i$ and $\\tilde{\\theta_i} = \\theta(y) = (b')^{-1}(y_i)$.\n",
    "$$l(\\tilde{\\mu},\\phi;y)=\\sum_{i=1}^{n}\\frac{y_{i}\\tilde{\\theta}_{i}-b(\\tilde{\\theta}_{i})}{a_{i}(\\phi)}+\\sum_{i=1}^{n}c(y_i,\\phi)$$\n",
    "\n",
    "Scale deviance statistics:\n",
    "$${S(y,\\hat{\\mu},\\phi)}=2\\left[l(\\tilde{\\mu},\\phi;y)-l(\\hat{\\mu},\\phi;y)\\right]\n",
    "=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}(\\phi)}.\n",
    "$$\n",
    "\n",
    "Deviance:\n",
    "Let $a_{i}(\\phi)=a_{i}\\phi$, then\n",
    "$$S(y,\\hat{\\mu},\\phi)=\\frac{D(y,\\hat{\\mu})}{\\phi},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "D(y,\\hat{\\mu})=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}}\n",
    "$$\n",
    "\n",
    "### Comparison of two models\n",
    "\n",
    "Assume model $D_0$ with $p_0$ paramters and its sub-model $D_1$ with $p_1$ parameters, then\n",
    "$$ \\frac{1}{\\phi} (D_0 - D_1) \\sim \\chi(p_0 - p_1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLxMlbIKeTe5"
   },
   "source": [
    "Question:\n",
    "* Can we take deviance as a measure of the model quality?\n",
    "* Can we use deviance as a measure of the saturated model quality?\n",
    "* Complete the sentence: Compare two GLMs with deviance is like compare two LMs with ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "5PVvXp_SpDUx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -125.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  30.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:05:26</td>     <th>  Pearson chi2:      </th>  <td>  30.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9715</td> <td>    0.130</td> <td>    7.461</td> <td> 0.000</td> <td>    0.716</td> <td>    1.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.2598</td> <td>    0.049</td> <td>   25.913</td> <td> 0.000</td> <td>    1.165</td> <td>    1.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0397</td> <td>    0.062</td> <td>    0.642</td> <td> 0.521</td> <td>   -0.081</td> <td>    0.161</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       37\n",
       "Model Family:                 Poisson   Df Model:                            2\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -125.03\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       30.859\n",
       "Time:                        18:05:26   Pearson chi2:                     30.4\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9715      0.130      7.461      0.000       0.716       1.227\n",
       "x1             1.2598      0.049     25.913      0.000       1.165       1.355\n",
       "x2             0.0397      0.062      0.642      0.521      -0.081       0.161\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add random variable to the previous model \n",
    "Z = scipy.stats.uniform.rvs(loc=0, scale=1, size=n*m)\n",
    "model_0 = sm.GLM(endog=Y, exog=np.hstack([X, Z[:, None]]), family=sm.families.Poisson()).fit()\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "_O24NMRTPjoA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -125.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  31.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:05:36</td>     <th>  Pearson chi2:      </th>  <td>  30.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9897</td> <td>    0.127</td> <td>    7.790</td> <td> 0.000</td> <td>    0.741</td> <td>    1.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.2606</td> <td>    0.049</td> <td>   25.952</td> <td> 0.000</td> <td>    1.165</td> <td>    1.356</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -125.23\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       31.271\n",
       "Time:                        18:05:36   Pearson chi2:                     30.9\n",
       "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9897      0.127      7.790      0.000       0.741       1.239\n",
       "x1             1.2606      0.049     25.952      0.000       1.165       1.356\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proposed model\n",
    "\n",
    "model_1 = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "WbtdZzD6Pjx6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    39</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -639.31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 01 Sep 2022</td> <th>  Deviance:          </th> <td>  1059.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:00:51</td>     <th>  Pearson chi2:      </th>  <td>  928.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.0060</td> <td>    0.021</td> <td>  187.769</td> <td> 0.000</td> <td>    3.964</td> <td>    4.048</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       39\n",
       "Model Family:                 Poisson   Df Model:                            0\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -639.31\n",
       "Date:                Thu, 01 Sep 2022   Deviance:                       1059.4\n",
       "Time:                        18:00:51   Pearson chi2:                     928.\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):              0.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.0060      0.021    187.769      0.000       3.964       4.048\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null model\n",
    "\n",
    "model_n = sm.GLM(endog=Y, exog=X[:, 0], family=sm.families.Poisson()).fit()\n",
    "model_n.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "508GBQM_Pj5L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/data/miniconda3/lib/python3.9/site-packages/statsmodels/regression/_tools.py:121: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  scale = np.dot(wresid, wresid) / df_resid\n"
     ]
    },
    {
     "ename": "PerfectSeparationError",
     "evalue": "Perfect separation detected, results not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPerfectSeparationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-21d94d237feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamilies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_deviance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/emanuel/data/miniconda3/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, maxiter, method, tol, scale, cov_type, cov_kwds, use_t, full_output, disp, max_start_irls, **kwargs)\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eim'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0mcov_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nonrobust'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m             return self._fit_irls(start_params=start_params, maxiter=maxiter,\n\u001b[0m\u001b[1;32m   1076\u001b[0m                                   \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m                                   cov_kwds=cov_kwds, use_t=use_t, **kwargs)\n",
      "\u001b[0;32m/media/emanuel/data/miniconda3/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py\u001b[0m in \u001b[0;36m_fit_irls\u001b[0;34m(self, start_params, maxiter, tol, scale, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Perfect separation detected, results not available\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mPerfectSeparationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m             converged = _check_convergence(criterion, iteration + 1, atol,\n\u001b[1;32m   1226\u001b[0m                                            rtol)\n",
      "\u001b[0;31mPerfectSeparationError\u001b[0m: Perfect separation detected, results not available"
     ]
    }
   ],
   "source": [
    "# Saturated model | cannot obtain\n",
    "\n",
    "I = np.diag(np.ones((m*n,)))\n",
    "\n",
    "model_s = sm.GLM(endog=Y, exog=I, family=sm.families.Poisson()).fit()\n",
    "model_s.summary2()\n",
    "model_s.null_deviance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWfxVEHguydO"
   },
   "source": [
    "For Poisson model:\n",
    "$$D = 2 \\sum_{i=1}^n y_i log( \\frac{y_i}{\\hat{\\mu_i}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "2Dm5NQ5Jr509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.859098247113582\n",
      "31.271047096272405\n"
     ]
    }
<<<<<<< HEAD
   ],
   "source": [
    "mu_est_0 = model_0.predict()\n",
    "mu_est_1 = model_1.predict()\n",
    "\n",
    "Dev_0 = 2*np.sum(Y*np.log(Y/mu_est_0))\n",
    "print(Dev_0)\n",
    "Dev_1 = 2*np.sum(Y*np.log(Y/mu_est_1))\n",
    "print(Dev_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9SuGMWFwhDM"
   },
   "source": [
    "## Anova testing \n",
    "from anova.glm?\n",
    "\n",
    "The table will optionally contain test statistics (and P values) comparing the reduction in deviance for the row to the residuals. For models with known dispersion (e.g., binomial and Poisson fits) the chi-squared test is most appropriate, and for those with dispersion estimated by moments (e.g., gaussian, quasibinomial and quasipoisson fits) the F test is most appropriate. \n",
    "\n",
    "Mallows' Cp statistic is the residual deviance plus twice the estimate of $sigma^2$ times the residual degrees of freedom, which is closely related to AIC (and a multiple of it if the dispersion is known). You can also choose \"LRT\" and \"Rao\" for likelihood ratio tests and Rao's efficient score test. The former is synonymous with \"Chisq\" (although both have an asymptotic chi-square distribution). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8MegJJTsqvK"
   },
   "outputs": [],
   "source": [
    "anova(model_1)\n",
    "anova(model_1, test = \"Cp\")\n",
    "anova(model_1, test = \"Chisq\")\n",
    "\n",
    "anova(model_1, model_0, test = \"Rao\")\n",
    "anova(model_1, model_0, test = \"LRT\")   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UchWeYjOxI7X"
   },
   "outputs": [],
   "source": [
    "# p-value of deviance tst\n",
    "# H0: model fit data\n",
    "p_dev <- pchisq(model_1$deviance, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "p_dev\n",
    "\n",
    "# critical value\n",
    "C_val <- qchisq(0.05, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "C_val\n",
    "\n",
    "#summary(model_1)\n",
    "#pchisq(1168 - 44, df=(39-38))\n",
    "\n",
    "anova(model_1,model_s, test = \"LRT\")   # saturated vs. final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7uXyJRAUKAd"
   },
   "outputs": [],
   "source": [
    "class anova():\n",
    "    def _call_(*models, test='F'):\n",
    "        if len(models) == 1:\n",
    "            \n",
    "    def _F_():\n",
    "        pass\n",
    "    def _chisq_():\n",
    "        pass\n",
    "    def _rao_():\n",
    "        pass\n",
    "    def _lrt_():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz4Ek6Y464bE"
   },
   "source": [
    "## Rao statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrTIUoUKUKDg"
   },
   "outputs": [],
   "source": [
    "######## Rao score statistics\n",
    "\n",
    "Rao <- sum((Y-mu_est_1)^2/mu_est_1)\n",
    "Rao\n",
    "# p-hodnota testu adekvatnosti modelu (pomoci Raovy statistiky)\n",
    "# H0: model dobre popisuje data\n",
    "prao <- pchisq(Rao, model$df.residual, ncp=0, lower.tail = FALSE); \n",
    "prao\n",
    "\n",
    "######  pomoci saturovaneho modelu\n",
    "anova(model_1,model_s, test = \"Rao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H73SzqdlUKIT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAmB4PDZJKEl"
   },
   "source": [
    "# Your turn:\n",
    "1. Generate data with followings parameters\n",
    " * $Y \\sim Poi(\\mu_i)$, where $E[Y_i] = \\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} = x_i^T \\beta \\  \\Rightarrow \\ q(\\mu_i) = \\mu_i =  x_i^T \\beta  = \\eta_i$\n",
    "* $X_{i1} \\sim N(50,10)$\n",
    "* $X_{i2} \\sim U(10,60)$\n",
    "* $X_{i3} \\sim Ber(0.45)$\n",
    "* $n = 40$\n",
    "2. Compute $\\hat{\\mu_i}$  for saturated, null,\"full\",\"best\" models.\n",
    "3. Compute Deviance, Rao, Wald statistics for your model and compare final model with the saturated and \"full\" ones.\n",
    "4. Generate 100x data for  $n \\in \\{20,40,60,80,100 \\}$ and plot $(\\hat{\\beta_i} -\\beta_i)$ vs. $(n)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O60Qhn1rV7Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3+qISYKNbOXYZbGEQmi1a",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01ZLMA_ex03.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
=======
  ]
>>>>>>> b8ac98bcd742d9d06ee2ed2e409465406c13e4fd
}
