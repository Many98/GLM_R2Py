{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Many98/GLM_R2Py/blob/main/Python/01ZLMA_ex03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-i6MbNFm4Zt"
   },
   "source": [
    "# 01ZLMA - Exercise 03\n",
    "Exercise 03 of the course 01ZLMA. \n",
    "\n",
    "## Contents\n",
    "\n",
    "* Statistical Inference\n",
    " ---\n",
    "* Testing\n",
    " ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "593Mg4ZbbeEE"
   },
   "source": [
    "#  Necessary theory recap from Lecture 04\n",
    "\n",
    "Under the conditions of regularity holds\n",
    "\n",
    "1.  $ \\ U(\\beta) \\sim N_{p}(0,I(\\beta)) \\Rightarrow  I^{-\\frac{1}{2}}(\\beta)\\, U(\\beta) {\\stackrel{D}{\\longrightarrow}} N_{p}(0, 1)$\n",
    "2. $ U(\\beta)I^{-1}(\\beta)U(\\beta)\\sim \\chi^{2}(p) \\Rightarrow U(\\beta)^T I^{-1}(\\beta)U(\\beta)  {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "3. Consistency of $\\hat{\\beta}$ and Wald statistics: \\\\\n",
    " $\\hat{\\beta}\\sim N_{p}(\\beta,I^{-1}(\\beta)) \\Rightarrow\n",
    "(\\hat{\\beta}-\\beta)^T I(\\beta)(\\hat{\\beta}-\\beta) {\\stackrel{D}{\\longrightarrow}} \\chi^{2}(p)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2c7jDIXSGGL"
   },
   "source": [
    "Saturated and null model\n",
    "\n",
    "* Null model: $\\mu_i = \\mu, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Null Model assumes one parameter for all of the data points, which means you only estimate 1 parameter. \n",
    "* Saturated model: $Y_i = \\hat{\\mu_i}, \\forall i \\in \\{1, \\ldots , n\\}$ \\\\\n",
    "The Saturated Model is a model that assumes each data point has its own parameters, which means you have n parameters to estimate.\n",
    "* Proposed Model:  model, where you try to explain your data points with $p$ parameters + an intercept term, so you have p+1 parameters, where $1 \\leq p \\leq n$.\n",
    "\n",
    "Questions:\n",
    "* What is the difference between null and saturated model?\n",
    "* Which model has greater log-likelihoood value?\n",
    "* Which model has the highest log-likelihood value?\n",
    "* What can you say about asymptotic distributions of $\\hat{\\beta}$ and $U(\\hat{\\beta})$ for saturated model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um9ho8cQHobx"
   },
   "source": [
    "## Let's code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-kZTsg7FZoM"
   },
   "source": [
    "Use Example 2 from the last Exercise 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n  = 20 # n observations\n",
    "m  = 2 # m parameters to estimate\n",
    "X1 = np.ones((n*m,))  # Intercept\n",
    "X2 = np.array([i for i in range(1, n+1)] * m) # Regressors\n",
    "X = np.vstack([X1, np.log(X2)]).T # design matrix\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m) # Response variable with Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jU_eFKcbWMUy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -118.52\n",
      "Date:                Sat, 03 Sep 2022   Deviance:                       19.573\n",
      "Time:                        18:00:52   Pearson chi2:                     19.8\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8079      0.133      6.076      0.000       0.547       1.068\n",
      "x1             1.3163      0.051     25.977      0.000       1.217       1.416\n",
      "==============================================================================\n",
      "estimated params are:[0.80787794 1.3162756 ]\n",
      "fitted values are:[  2.24314285   5.58592849   9.52532934  13.91021399  18.65924629\n",
      "  23.72020508  29.0562033   34.63955072  40.44856027  46.4657056\n",
      "  52.67647657  59.06862737  65.63166037  72.35645896  79.23501871\n",
      "  86.26024551  93.42580091 100.72598134 108.1556224  115.7100219\n",
      "   2.24314285   5.58592849   9.52532934  13.91021399  18.65924629\n",
      "  23.72020508  29.0562033   34.63955072  40.44856027  46.4657056\n",
      "  52.67647657  59.06862737  65.63166037  72.35645896  79.23501871\n",
      "  86.26024551  93.42580091 100.72598134 108.1556224  115.7100219 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to create models we can use standard api or formula (r-like) api in statsmodels\n",
    "# formula api requires dataset (pandas) and formula\n",
    "d = pd.DataFrame(data={'Y': Y, 'X1': X1, 'X2':X2})\n",
    "#model = smf.glm(formula='Y~np.log(X2)', data=d, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# standard api requires specifying endog (response) and exog (explanatory) design matrices\n",
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "beta_e = model.params; print(f'estimated params are:{beta_e}')\n",
    "y_hat = model.predict(); print(f'fitted values are:{y_hat}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2, Y, color='red', marker='o')\n",
    "ax.plot(np.unique(y_hat), color='blue')\n",
    "ax.set_title('Poisson model')\n",
    "ax.set_xlabel('Year Quoter')\n",
    "ax.set_ylabel('Number of cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N8x-oi3HAKK"
   },
   "source": [
    "Repetition using custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calcualate weights W\n",
    "def calc_W_inv(X, beta):\n",
    "    return np.diag(np.exp(X @ beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xcA9wuh1WMtL"
   },
   "outputs": [],
   "source": [
    "# function to calcualate weights Z\n",
    "def calc_Z(X,Y,beta):\n",
    "    return X@beta + (Y - np.exp(X@beta)) / np.exp(X@beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "igkUvl36XAGV"
   },
   "outputs": [],
   "source": [
    "# IWLS for example 2\n",
    "\n",
    "def IWLS(X,Y,beta_init,maxiter,epsilon):\n",
    "    res = {'FM': None, 'SV': None, 'betas': None}\n",
    "    # Fisher-scoring algorithm\n",
    "    i = 1     # first iteration\n",
    "\n",
    "    beta_i = beta_init\n",
    "    \n",
    "    while i <= maxiter:\n",
    "        W = calc_W_inv(X,beta_i)\n",
    "        Z = calc_Z(X,Y,beta_i)\n",
    "        beta_pred = beta_i\n",
    "        beta_i = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        diff = np.max(np.abs(beta_i - beta_pred))\n",
    "        if diff < epsilon:\n",
    "            break\n",
    "        W = calc_W_inv(X, beta_i)\n",
    "        Z = calc_Z(X, Y, beta_i)\n",
    "\n",
    "        res['SV'] = X.T@W@Z\n",
    "        res['FM'] = X.T@W@X\n",
    "        res['betas'] = np.linalg.solve(X.T@W@X, X.T@W@Z)\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1VDw0-mqZF7x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of parameters: [0.80787794 1.3162756 ]\n",
      "Estimated Fisher information matrix: [[ 2115.          5475.27622876]\n",
      " [ 5475.27622876 14563.78984362]]\n",
      "Estimated covariance matrix: [[ 0.01767953 -0.00664664]\n",
      " [-0.00664664  0.00256748]]\n"
     ]
    }
   ],
   "source": [
    "# Estimation of betas\n",
    "result1 = IWLS(X,Y,np.ones(2),100,10^(-6))\n",
    "print(f'Estimation of parameters: {result1[\"betas\"]}')      # Estimation of parameters\n",
    "print(f'Estimated Fisher information matrix: {result1[\"FM\"]}')        # Estimated Fisher information matrix\n",
    "print(f'Estimated covariance matrix: {np.linalg.inv(result1[\"FM\"])}')  # Estimated covariance matrix  = Inverse of estimated Fisher information matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEUlAqmFH_mB"
   },
   "source": [
    "Comparison of our custom solution with the built in glm function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6E-UbtQQXALw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -118.52\n",
      "Date:                Sat, 03 Sep 2022   Deviance:                       19.573\n",
      "Time:                        18:00:53   Pearson chi2:                     19.8\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8079      0.133      6.076      0.000       0.547       1.068\n",
      "x1             1.3163      0.051     25.977      0.000       1.217       1.416\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.01767946 -0.00664662]\n",
      " [-0.00664662  0.00256747]]\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aic\n",
      "bic\n",
      "bic_deviance\n",
      "bic_llf\n",
      "bse\n",
      "conf_int\n",
      "converged\n",
      "cov_kwds\n",
      "cov_params\n",
      "cov_type\n",
      "deviance\n",
      "df_model\n",
      "df_resid\n",
      "f_test\n",
      "family\n",
      "fit_history\n",
      "fittedvalues\n",
      "get_hat_matrix_diag\n",
      "get_influence\n",
      "get_prediction\n",
      "info_criteria\n",
      "initialize\n",
      "k_constant\n",
      "llf\n",
      "llf_scaled\n",
      "llnull\n",
      "load\n",
      "method\n",
      "mle_settings\n",
      "model\n",
      "mu\n",
      "nobs\n",
      "normalized_cov_params\n",
      "null\n",
      "null_deviance\n",
      "params\n",
      "pearson_chi2\n",
      "plot_added_variable\n",
      "plot_ceres_residuals\n",
      "plot_partial_residuals\n",
      "predict\n",
      "pseudo_rsquared\n",
      "pvalues\n",
      "remove_data\n",
      "resid_anscombe\n",
      "resid_anscombe_scaled\n",
      "resid_anscombe_unscaled\n",
      "resid_deviance\n",
      "resid_pearson\n",
      "resid_response\n",
      "resid_working\n",
      "save\n",
      "scale\n",
      "summary\n",
      "summary2\n",
      "t_test\n",
      "t_test_pairwise\n",
      "tvalues\n",
      "use_t\n",
      "wald_test\n",
      "wald_test_terms\n"
     ]
    }
   ],
   "source": [
    "# to find out what params has `model` object\n",
    "for attr in dir(model):\n",
    "    if not attr.startswith('_'):\n",
    "        print(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7vo_sJaOFiL"
   },
   "source": [
    "Asymptotics:\n",
    "\n",
    "* $ (\\hat{\\beta} - \\beta) \\sim N_{p}(0, I^{-1}(\\beta))$ \n",
    "* Estimated Fisher information matrix  $\\hat{I}(\\hat{\\beta}) = (X^T \\hat{W} X)$  matrix.\n",
    "*  Estimated covariance matrix $\\hat{V} (\\hat{\\beta}) = (X^T \\hat{W} X)^{-1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kB52Ef03Z7uO"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "repet = 50\n",
    "n_observ = np.array([1,2,5,10,100, 500])\n",
    "betas_hat = np.zeros((6, repet, 2))\n",
    "\n",
    "for _, i in enumerate(n_observ):\n",
    "    for j in range(repet):\n",
    "        X1 = np.ones((n*i,))\n",
    "        X2 = np.array([i for i in range(1, n+1)]*i)\n",
    "        X  = np.vstack([X1, np.log(X2)]).T\n",
    "        beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "        lamdas = np.exp(X @ beta) # Means\n",
    "        Y = np.random.poisson(lamdas, n*i)\n",
    "        betas_hat[_, j] = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit().params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nkafuLnXZ7xG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 10\n",
      "[[ 0.06444145 -0.03109597]\n",
      " [-0.03109597  0.01611895]]\n",
      "0.008330369352331961\n",
      "Number of observations: 20\n",
      "[[ 0.04380673 -0.02140931]\n",
      " [-0.02140931  0.01083468]]\n",
      "0.005453865374317191\n",
      "Number of observations: 50\n",
      "[[ 0.01484336 -0.00770914]\n",
      " [-0.00770914  0.00418468]]\n",
      "-0.0017041343074835657\n",
      "Number of observations: 100\n",
      "[[ 0.0086264  -0.00425775]\n",
      " [-0.00425775  0.00218247]]\n",
      "-0.0025229516345396143\n",
      "Number of observations: 1000\n",
      "[[ 0.00146265 -0.0007335 ]\n",
      " [-0.0007335   0.00037602]]\n",
      "0.0011531601930317614\n",
      "Number of observations: 5000\n",
      "[[ 2.05562714e-04 -1.06502108e-04]\n",
      " [-1.06502108e-04  5.75415090e-05]]\n",
      "-0.000398511838356842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(n_observ)):\n",
    "    print(f\"Number of observations: {n_observ[i]*n}\")\n",
    "    print(np.cov((betas_hat[i] - beta).T))\n",
    "    print(np.mean(betas_hat[i] - beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TjcOg79UPRM"
   },
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Use the model from the beginning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8rwWB0Grrmnt"
   },
   "outputs": [],
   "source": [
    "n  = 20\n",
    "m  = 2\n",
    "\n",
    "X1 = np.ones((n*m,))\n",
    "X2 = np.array([i for i in range(1, n+1)]*m)\n",
    "X  = np.vstack([X1, np.log(X2)]).T\n",
    "beta = np.array([0.9, 1.3]) # Regression coefficients\n",
    "lamdas = np.exp(X @ beta) # Means\n",
    "Y = np.random.poisson(lamdas, n*m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2opFFdr0UfhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       38\n",
      "Model Family:                 Poisson   Df Model:                            1\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -133.53\n",
      "Date:                Sat, 03 Sep 2022   Deviance:                       49.362\n",
      "Time:                        18:00:54   Pearson chi2:                     48.5\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.7312      0.133      5.491      0.000       0.470       0.992\n",
      "x1             1.3607      0.051     26.881      0.000       1.261       1.460\n",
      "==============================================================================\n",
      "estimated covariance matrix [[ 0.01773342 -0.00665372]\n",
      " [-0.00665372  0.00256226]]\n"
     ]
    }
   ],
   "source": [
    "model = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# the unscaled (dispersion = 1) estimated covariance matrix of the estimated coefficients.\n",
    "FIM1 = model.cov_params()\n",
    "print(f'estimated covariance matrix {FIM1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR3DTTTWV94T"
   },
   "source": [
    "Calculation of Z value\n",
    " $$Z_i = \\frac{\\hat{\\beta_i}}{(I^{-1}(\\hat{\\beta_i}))_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lv8guvybUK-E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -133.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 03 Sep 2022</td> <th>  Deviance:          </th> <td>  49.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:00:54</td>     <th>  Pearson chi2:      </th>  <td>  48.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7312</td> <td>    0.133</td> <td>    5.491</td> <td> 0.000</td> <td>    0.470</td> <td>    0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3607</td> <td>    0.051</td> <td>   26.881</td> <td> 0.000</td> <td>    1.261</td> <td>    1.460</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -133.53\n",
       "Date:                Sat, 03 Sep 2022   Deviance:                       49.362\n",
       "Time:                        18:00:54   Pearson chi2:                     48.5\n",
       "No. Iterations:                     6   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7312      0.133      5.491      0.000       0.470       0.992\n",
       "x1             1.3607      0.051     26.881      0.000       1.261       1.460\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing statistics from summary table\n",
    "model.summary()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dNjECz1FNw_c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.49104794 26.88102202]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By definition\n",
    "\n",
    "z_stat = model.params / np.sqrt(np.diag(model.cov_params()))\n",
    "print(z_stat)\n",
    "z_stat == model.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9mHfejdWULDh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval: [3.99555882e-008 3.66111009e-159]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-values of the test\n",
    "p_val = 2*scipy.stats.norm.sf(z_stat, loc=0, scale=1)\n",
    "print(f'pval: {p_val}')\n",
    "p_val == model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7GdfbeqdYOIv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5% CI = 1.2614738044805862,ESTIM = 1.360684809928891, 97.5% CI = 1.459895815377196\n",
      "[[0.47022347 0.9922281 ]\n",
      " [1.2614738  1.45989582]]\n"
     ]
    }
   ],
   "source": [
    "### 100(1-alpha) confidence interval\n",
    "alpha = 0.05\n",
    "u = scipy.stats.norm.ppf(1-alpha/2,0,1)\n",
    "CI_LB = model.params[1] - u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "CI_UB = model.params[1] + u * np.sqrt(np.diag(model.cov_params())[1])\n",
    "\n",
    "print(f\"2.5% CI = {CI_LB},ESTIM = {model.params[1]}, 97.5% CI = {CI_UB}\")\n",
    "\n",
    "\n",
    "# built in function\n",
    "print(model.conf_int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkhFJFXceHjn"
   },
   "source": [
    "Question:\n",
    "\n",
    "* Compare hypothesis testing in LM vs. GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwXaIg0peQee"
   },
   "source": [
    "# Deviance\n",
    "\n",
    "Deviance is a measure of goodness of fit of a GLM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjNUyZoZeStY"
   },
   "source": [
    "Log-likelihood of the saturated model is the highest possible one with given data, $\\tilde{\\mu}_i = y_i$ and $\\tilde{\\theta_i} = \\theta(y) = (b')^{-1}(y_i)$.\n",
    "$$l(\\tilde{\\mu},\\phi;y)=\\sum_{i=1}^{n}\\frac{y_{i}\\tilde{\\theta}_{i}-b(\\tilde{\\theta}_{i})}{a_{i}(\\phi)}+\\sum_{i=1}^{n}c(y_i,\\phi)$$\n",
    "\n",
    "Scale deviance statistics:\n",
    "$${S(y,\\hat{\\mu},\\phi)}=2\\left[l(\\tilde{\\mu},\\phi;y)-l(\\hat{\\mu},\\phi;y)\\right]\n",
    "=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}(\\phi)}.\n",
    "$$\n",
    "\n",
    "Deviance:\n",
    "Let $a_{i}(\\phi)=a_{i}\\phi$, then\n",
    "$$S(y,\\hat{\\mu},\\phi)=\\frac{D(y,\\hat{\\mu})}{\\phi},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "D(y,\\hat{\\mu})=2\\sum_{i=1}^{n}\\frac{y_{i}(\\tilde{\\theta}_{i}-\\hat{\\theta}_{i})\n",
    "-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)}{a_{i}}\n",
    "$$\n",
    "\n",
    "### Comparison of two models\n",
    "\n",
    "Assume model $D_0$ with $p_0$ paramters and its sub-model $D_1$ with $p_1$ parameters, then\n",
    "$$ \\frac{1}{\\phi} (D_0 - D_1) \\sim \\chi(p_0 - p_1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLxMlbIKeTe5"
   },
   "source": [
    "Question:\n",
    "* Can we take deviance as a measure of the model quality?\n",
    "* Can we use deviance as a measure of the saturated model quality?\n",
    "* Complete the sentence: Compare two GLMs with deviance is like compare two LMs with ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5PVvXp_SpDUx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -133.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 03 Sep 2022</td> <th>  Deviance:          </th> <td>  48.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:00:54</td>     <th>  Pearson chi2:      </th>  <td>  47.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7069</td> <td>    0.135</td> <td>    5.217</td> <td> 0.000</td> <td>    0.441</td> <td>    0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3579</td> <td>    0.051</td> <td>   26.833</td> <td> 0.000</td> <td>    1.259</td> <td>    1.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0646</td> <td>    0.069</td> <td>    0.931</td> <td> 0.352</td> <td>   -0.071</td> <td>    0.201</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       37\n",
       "Model Family:                 Poisson   Df Model:                            2\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -133.09\n",
       "Date:                Sat, 03 Sep 2022   Deviance:                       48.495\n",
       "Time:                        18:00:54   Pearson chi2:                     47.7\n",
       "No. Iterations:                     6   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7069      0.135      5.217      0.000       0.441       0.972\n",
       "x1             1.3579      0.051     26.833      0.000       1.259       1.457\n",
       "x2             0.0646      0.069      0.931      0.352      -0.071       0.201\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add random variable to the previous model \n",
    "Z = scipy.stats.uniform.rvs(loc=0, scale=1, size=n*m)\n",
    "model_0 = sm.GLM(endog=Y, exog=np.hstack([X, Z[:, None]]), family=sm.families.Poisson()).fit()\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "_O24NMRTPjoA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -133.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 03 Sep 2022</td> <th>  Deviance:          </th> <td>  49.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:52:13</td>     <th>  Pearson chi2:      </th>  <td>  48.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>  Pseudo R-squ. (CS):</th>  <td> 1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7312</td> <td>    0.133</td> <td>    5.491</td> <td> 0.000</td> <td>    0.470</td> <td>    0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.3607</td> <td>    0.051</td> <td>   26.881</td> <td> 0.000</td> <td>    1.261</td> <td>    1.460</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       38\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -133.53\n",
       "Date:                Sat, 03 Sep 2022   Deviance:                       49.362\n",
       "Time:                        18:52:13   Pearson chi2:                     48.5\n",
       "No. Iterations:                     6   Pseudo R-squ. (CS):              1.000\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7312      0.133      5.491      0.000       0.470       0.992\n",
       "x1             1.3607      0.051     26.881      0.000       1.261       1.460\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proposed model\n",
    "m1 = sm.GLM(endog=Y, exog=X, family=sm.families.Poisson())\n",
    "model_1 = m1.fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WbtdZzD6Pjx6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>    40</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>   <td>    39</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>   <td>     0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th>  <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th>  <td> -701.15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 03 Sep 2022</td> <th>  Deviance:          </th>  <td>  1184.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:00:54</td>     <th>  Pearson chi2:      </th>  <td>1.07e+03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th> <td>-5.684e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.0064</td> <td>    0.021</td> <td>  187.833</td> <td> 0.000</td> <td>    3.965</td> <td>    4.048</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   40\n",
       "Model:                            GLM   Df Residuals:                       39\n",
       "Model Family:                 Poisson   Df Model:                            0\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -701.15\n",
       "Date:                Sat, 03 Sep 2022   Deviance:                       1184.6\n",
       "Time:                        18:00:54   Pearson chi2:                 1.07e+03\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):         -5.684e-14\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.0064      0.021    187.833      0.000       3.965       4.048\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null model\n",
    "\n",
    "model_n = sm.GLM(endog=Y, exog=X[:, 0], family=sm.families.Poisson()).fit()\n",
    "model_n.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "508GBQM_Pj5L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                        0\n",
      "Model Family:                 Poisson   Df Model:                           39\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -108.85\n",
      "Date:                Sat, 03 Sep 2022   Deviance:                   7.6383e-14\n",
      "Time:                        18:00:54   Pearson chi2:                 1.19e-27\n",
      "No. Iterations:                     8   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1         -3.644e-17      1.000  -3.64e-17      1.000      -1.960       1.960\n",
      "x2             1.3863      0.500      2.773      0.006       0.406       2.366\n",
      "x3             2.3979      0.302      7.953      0.000       1.807       2.989\n",
      "x4             2.8904      0.236     12.263      0.000       2.428       3.352\n",
      "x5             2.4849      0.289      8.608      0.000       1.919       3.051\n",
      "x6             3.1781      0.204     15.569      0.000       2.778       3.578\n",
      "x7             3.3322      0.189     17.632      0.000       2.962       3.703\n",
      "x8             3.3673      0.186     18.133      0.000       3.003       3.731\n",
      "x9             3.7377      0.154     24.223      0.000       3.435       4.040\n",
      "x10            3.7842      0.151     25.101      0.000       3.489       4.080\n",
      "x11            4.2047      0.122     34.417      0.000       3.965       4.444\n",
      "x12            4.0943      0.129     31.715      0.000       3.841       4.347\n",
      "x13            4.3307      0.115     37.754      0.000       4.106       4.556\n",
      "x14            4.3567      0.113     38.477      0.000       4.135       4.579\n",
      "x15            4.5951      0.101     45.721      0.000       4.398       4.792\n",
      "x16            4.5951      0.101     45.721      0.000       4.398       4.792\n",
      "x17            4.5218      0.104     43.371      0.000       4.317       4.726\n",
      "x18            4.6821      0.096     48.658      0.000       4.494       4.871\n",
      "x19            4.7362      0.094     50.569      0.000       4.553       4.920\n",
      "x20            4.9273      0.085     57.882      0.000       4.760       5.094\n",
      "x21            1.0986      0.577      1.903      0.057      -0.033       2.230\n",
      "x22            2.0794      0.354      5.882      0.000       1.386       2.772\n",
      "x23            2.1972      0.333      6.592      0.000       1.544       2.851\n",
      "x24            2.7081      0.258     10.488      0.000       2.202       3.214\n",
      "x25            2.6391      0.267      9.874      0.000       2.115       3.163\n",
      "x26            3.2581      0.196     16.613      0.000       2.874       3.642\n",
      "x27            3.2958      0.192     17.126      0.000       2.919       3.673\n",
      "x28            3.5264      0.171     20.562      0.000       3.190       3.862\n",
      "x29            3.7136      0.156     23.778      0.000       3.407       4.020\n",
      "x30            4.0254      0.134     30.123      0.000       3.763       4.287\n",
      "x31            4.2905      0.117     36.658      0.000       4.061       4.520\n",
      "x32            3.9120      0.141     27.662      0.000       3.635       4.189\n",
      "x33            3.9318      0.140     28.079      0.000       3.657       4.206\n",
      "x34            3.9120      0.141     27.662      0.000       3.635       4.189\n",
      "x35            4.5326      0.104     43.711      0.000       4.329       4.736\n",
      "x36            4.3307      0.115     37.754      0.000       4.106       4.556\n",
      "x37            4.5218      0.104     43.371      0.000       4.317       4.726\n",
      "x38            4.7274      0.094     50.253      0.000       4.543       4.912\n",
      "x39            4.6347      0.099     47.037      0.000       4.442       4.828\n",
      "x40            4.7875      0.091     52.444      0.000       4.609       4.966\n",
      "==============================================================================\n",
      "Residual deviance is: 7.638334409420956e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/emanuel/data/miniconda3/lib/python3.9/site-packages/statsmodels/regression/_tools.py:121: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  scale = np.dot(wresid, wresid) / df_resid\n"
     ]
    }
   ],
   "source": [
    "# Saturated model CANNOT BY OBTAINED BY STATSMODELS BY DEFAULT 'CAUSE THEY PREVENT ZERO DIVISION\n",
    "\n",
    "# BUT MY WORKAROUND WHICH PROBABLY WILL NOT WORK IN COLAB AS WE DO NOT HAVE ACCESS TO MODULES IS\n",
    "# TO COMMENT OUT ROWS 1227-1229 IN MOST RECENT VERSION \n",
    "# (SEE https://github.com/statsmodels/statsmodels/blob/main/statsmodels/genmod/generalized_linear_model.py)\n",
    "\n",
    "I = np.diag(np.ones((m*n,)))\n",
    "\n",
    "\n",
    "model_s = sm.GLM(endog=Y, exog=I, family=sm.families.Poisson()).fit()\n",
    "print(model_s.summary())\n",
    "print(f'Residual deviance is: {model_s.deviance}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWfxVEHguydO"
   },
   "source": [
    "For Poisson model:\n",
    "$$D = 2 \\sum_{i=1}^n y_i log( \\frac{y_i}{\\hat{\\mu_i}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2Dm5NQ5Jr509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.494759469850976\n",
      "49.36227563895237\n"
     ]
    }
   ],
   "source": [
    "mu_est_0 = model_0.predict()\n",
    "mu_est_1 = model_1.predict()\n",
    "\n",
    "Dev_0 = 2*np.sum(Y*np.log(Y/mu_est_0))\n",
    "print(Dev_0)\n",
    "Dev_1 = 2*np.sum(Y*np.log(Y/mu_est_1))\n",
    "print(Dev_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9SuGMWFwhDM"
   },
   "source": [
    "## Anova testing \n",
    "from anova.glm?\n",
    "\n",
    "The table will optionally contain test statistics (and P values) comparing the reduction in deviance for the row to the residuals. For models with known dispersion (e.g., binomial and Poisson fits) the chi-squared test is most appropriate, and for those with dispersion estimated by moments (e.g., gaussian, quasibinomial and quasipoisson fits) the F test is most appropriate. \n",
    "\n",
    "Mallows' Cp statistic is the residual deviance plus twice the estimate of $sigma^2$ times the residual degrees of freedom, which is closely related to AIC (and a multiple of it if the dispersion is known). You can also choose \"LRT\" and \"Rao\" for likelihood ratio tests and Rao's efficient score test. The former is synonymous with \"Chisq\" (although both have an asymptotic chi-square distribution). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "u8MegJJTsqvK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anova' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c1e6e4bf8e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Chisq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0manova\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Rao\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anova' is not defined"
     ]
    }
   ],
   "source": [
    "anova(model_1)\n",
    "anova(model_1, test = \"Cp\")\n",
    "anova(model_1, test = \"Chisq\")\n",
    "\n",
    "anova(model_1, model_0, test = \"Rao\")\n",
    "anova(model_1, model_0, test = \"LRT\")   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UchWeYjOxI7X"
   },
   "outputs": [],
   "source": [
    "# p-value of deviance tst\n",
    "# H0: model fit data\n",
    "p_dev <- pchisq(model_1$deviance, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "p_dev\n",
    "\n",
    "# critical value\n",
    "C_val <- qchisq(0.05, model_1$df.residual, ncp=0, lower.tail = FALSE)\n",
    "C_val\n",
    "\n",
    "#summary(model_1)\n",
    "#pchisq(1168 - 44, df=(39-38))\n",
    "\n",
    "anova(model_1,model_s, test = \"LRT\")   # saturated vs. final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7uXyJRAUKAd"
   },
   "outputs": [],
   "source": [
    "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/anova.glm\n",
    "\n",
    "class anova():\n",
    "    def _call_(*models, test='chisq'):\n",
    "        if len(models) == 1:\n",
    "            \"\"\"Testing quality of model\"\"\"\n",
    "            res = _fork(*models, test)\n",
    "        elif len(models) > 1:\n",
    "            \"\"\"Comparing models\"\"\"\n",
    "        else:\n",
    "            raise Exception('None model selected')\n",
    "    def __str__():\n",
    "        pass\n",
    "    def _warnings():\n",
    "        pass\n",
    "    def _fork(*models, test):\n",
    "        if test.lower() in ('chisq'.lower(), 'lrt'):\n",
    "            res = _chisq_()\n",
    "        elif test.lower() == 'rao':\n",
    "            res = _rao_()\n",
    "        elif test.lower() == 'cp'\n",
    "            res = _cp_()\n",
    "        else:\n",
    "            raise Exception(f'Not such test implemented: {test}')\n",
    "        return res\n",
    "    def _score_():\n",
    "        pass\n",
    "    def _fisher_():\n",
    "        pass\n",
    "    def _F_(*models):\n",
    "        \"\"\"Performs deviance F-test most appropriate when scale param (phi) is not known\"\"\"\n",
    "        phi_hat  = models[-1].deviance / (models[-1].nobs - models[-1].df_resid)\n",
    "        f_stat = (models[0].deviance - models[-1].deviance) / ((models[-1].df_resid - models[0].df_resid)* phi_hat)\n",
    "        p_val = scipy.stats.f.sf(f_stat, dfn=models[-1].df_resid - models[0].df_resid, \n",
    "                                 dfd=models[-1].nobs - models[-1].df_resid)\n",
    "        return {'F_stat': f_stat, 'p_val': p_val}\n",
    "    def _chisq_(*models):\n",
    "        \"\"\"Performs deviance LRT test leading to Chisq test statistic (known dispersion param)\n",
    "            Note that if disperzion param is not known then deviance LRT test leads to F test and\n",
    "            performing Chisq test is inappropriate\n",
    "        \"\"\"\n",
    "        chi2_stat = (models[0].deviance - models[-1].deviance) / models[0].scale\n",
    "        p_val = scipy.stats.chi2.sf(chi2_stat, df=models[-1].df_resid - models[0].df_resid)\n",
    "        print(f'Estimated F statistic is: {f_stat} \\n'\n",
    "              f'P-value is: {p_val} \\n'\n",
    "              )\n",
    "    def _rao_():\n",
    "        raise Exception('Currently not implemented')\n",
    "    def _cp_():\n",
    "        raise Exception('Currently not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz4Ek6Y464bE"
   },
   "source": [
    "## Rao statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "GrTIUoUKUKDg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rao score statistic: 48.46844903288136\n",
      "p-val of rao test: 0.11891923476215518\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GLMResults' object has no attribute 'score_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-8a4bfa8c84ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m######  pomoci saturovaneho modelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#anova(model_1,model_s, test = \"Rao\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/emanuel/data/miniconda3/lib/python3.9/site-packages/statsmodels/base/wrapper.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_attrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLMResults' object has no attribute 'score_test'"
     ]
    }
   ],
   "source": [
    "######## Rao score statistics\n",
    "\n",
    "score = model_1.resid_response / model_1.model.family.variance(model_1.predict())\n",
    "rao = score.T @  np.diag(model_1.model.family.variance(model_1.predict())) @ score\n",
    "print(f'rao score statistic: {rao}')\n",
    "\n",
    "# p-hodnota testu adekvatnosti modelu (pomoci Raovy statistiky)\n",
    "# H0: model dobre popisuje data\n",
    "\n",
    "print(f'p-val of rao test: {scipy.stats.chi2.sf(rao, df=model_1.df_resid)}')\n",
    "\n",
    "######  pomoci saturovaneho modelu\n",
    "model_1.score_test()\n",
    "#anova(model_1,model_s, test = \"Rao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.07762577,   5.33548946,   9.26358238,  13.7019131 ,\n",
       "        18.56287292,  23.78953264,  29.34130257,  35.18747886,\n",
       "        41.3038573 ,  47.67076638,  54.27183825,  61.09319705,\n",
       "        68.12289921,  75.35053364,  82.76692784,  90.36392651,\n",
       "        98.1342213 , 106.07121755, 114.16892832, 122.42188896,\n",
       "         2.07762577,   5.33548946,   9.26358238,  13.7019131 ,\n",
       "        18.56287292,  23.78953264,  29.34130257,  35.18747886,\n",
       "        41.3038573 ,  47.67076638,  54.27183825,  61.09319705,\n",
       "        68.12289921,  75.35053364,  82.76692784,  90.36392651,\n",
       "        98.1342213 , 106.07121755, 114.16892832, 122.42188896])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.model.family.variance(model_1.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.07762577,  -1.33548946,   1.73641762,   4.2980869 ,\n",
       "        -6.56287292,   0.21046736,  -1.34130257,  -6.18747886,\n",
       "         0.6961427 ,  -3.67076638,  12.72816175,  -1.09319705,\n",
       "         7.87710079,   2.64946636,  16.23307216,   8.63607349,\n",
       "        -6.1342213 ,   1.92878245,  -0.16892832,  15.57811104,\n",
       "         0.92237423,   2.66451054,  -0.26358238,   1.2980869 ,\n",
       "        -4.56287292,   2.21046736,  -2.34130257,  -1.18747886,\n",
       "        -0.3038573 ,   8.32923362,  18.72816175, -11.09319705,\n",
       "       -17.12289921, -25.35053364,  10.23307216, -14.36392651,\n",
       "        -6.1342213 ,   6.92878245, -11.16892832,  -2.42188896])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y-mu_est_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.07762577,  -1.33548946,   1.73641762,   4.2980869 ,\n",
       "        -6.56287292,   0.21046736,  -1.34130257,  -6.18747886,\n",
       "         0.6961427 ,  -3.67076638,  12.72816175,  -1.09319705,\n",
       "         7.87710079,   2.64946636,  16.23307216,   8.63607349,\n",
       "        -6.1342213 ,   1.92878245,  -0.16892832,  15.57811104,\n",
       "         0.92237423,   2.66451054,  -0.26358238,   1.2980869 ,\n",
       "        -4.56287292,   2.21046736,  -2.34130257,  -1.18747886,\n",
       "        -0.3038573 ,   8.32923362,  18.72816175, -11.09319705,\n",
       "       -17.12289921, -25.35053364,  10.23307216, -14.36392651,\n",
       "        -6.1342213 ,   6.92878245, -11.16892832,  -2.42188896])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.resid_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.46844903288135"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.resid_pearson @ model_1.resid_pearson.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _F_(*models, estim_scale=False):\n",
    "        \"\"\"Performs deviance F-test most appropriate when scale param (phi) is not known\"\"\"\n",
    "        phi_hat = models[0].scale\n",
    "        if estim_scale:\n",
    "            phi_hat  = models[-1].deviance / (models[-1].nobs - models[-1].df_model)\n",
    "    \n",
    "        f_stat = (models[0].deviance - models[-1].deviance) / ((models[-1].df_model - models[0].df_model)* phi_hat)\n",
    "        p_val = scipy.stats.f.sf(f_stat, dfn=models[-1].df_model - models[0].df_model, \n",
    "                                 dfd=models[-1].nobs - models[-1].df_model)\n",
    "        print(f'Estimated F statistic is: {f_stat} \\n'\n",
    "              f'P-value is: {p_val} \\n'\n",
    "              )\n",
    "def _chisq_(*models):\n",
    "    \"\"\"Performs deviance LRT test leading to Chisq test statistic (known dispersion param)\n",
    "        Note that if disperzion param is not known then deviance LRT test leads to F test and\n",
    "        performing Chisq test is inappropriate\n",
    "    \"\"\"\n",
    "    chi2_stat = (models[0].deviance - models[-1].deviance) / models[0].scale\n",
    "    p_val = scipy.stats.chi2.sf(chi2_stat, df=models[-1].df_model - models[0].df_model)\n",
    "    print(f'Estimated Chi2 statistic is: {chi2_stat} \\n'\n",
    "          f'P-value is: {p_val} \\n'\n",
    "          )\n",
    "\n",
    "def _rao_(*models):\n",
    "    scores = [i.resid_response / i.model.family.variance(i.predict()) for i in models]\n",
    "    raos = [i.T  @ np.diag(j.model.family.variance(j.predict())) @ i for i, j in zip(scores, models)]\n",
    "    \n",
    "    chi2_stat = (raos[0] - raos[-1]) / models[0].scale\n",
    "    p_val = scipy.stats.chi2.sf(chi2_stat, df=models[-1].df_model - models[0].df_model)\n",
    "    print(f'Estimated Rao statistic is: {chi2_stat} \\n'\n",
    "          f'P-value is: {p_val} \\n'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Rao statistic is: 0.7584077948718644 \n",
      "P-value is: 0.6161727410972954 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_rao_(model_1, model_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<Wald test (chi2): statistic=626.2068650098701, p-value=3.340391444300058e-138, df_denom=1>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.array(([1,1]))\n",
    "model_1.wald_test(R, scalar=True)\n",
    "#model_0.deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated F statistic is: 1135.2536376115138 \n",
      "P-value is: 1.8879825021417397e-30 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_F_(model_n, model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAmB4PDZJKEl"
   },
   "source": [
    "# Your turn:\n",
    "1. Generate data with followings parameters\n",
    " * $Y \\sim Poi(\\mu_i)$, where $E[Y_i] = \\mu_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} = x_i^T \\beta \\  \\Rightarrow \\ q(\\mu_i) = \\mu_i =  x_i^T \\beta  = \\eta_i$\n",
    "* $X_{i1} \\sim N(50,10)$\n",
    "* $X_{i2} \\sim U(10,60)$\n",
    "* $X_{i3} \\sim Ber(0.45)$\n",
    "* $n = 40$\n",
    "2. Compute $\\hat{\\mu_i}$  for saturated, null,\"full\",\"best\" models.\n",
    "3. Compute Deviance, Rao, Wald statistics for your model and compare final model with the saturated and \"full\" ones.\n",
    "4. Generate 100x data for  $n \\in \\{20,40,60,80,100 \\}$ and plot $(\\hat{\\beta_i} -\\beta_i)$ vs. $(n)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O60Qhn1rV7Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3+qISYKNbOXYZbGEQmi1a",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "01ZLMA_ex03.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
